{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MenE2varZEXc"
   },
   "source": [
    "# Transformers From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTSadDXiPQLm"
   },
   "source": [
    "This lab builds a sequence to sequence transformer, with encoder-decoder blocks from scratch for translation from Portuguese to English. Transformers excel at modeling sequential data, such as natural language. The datasets is from the TED Talks Open Translation Project. This dataset contains approximately 52,000 training, 1,200 validation and 1,800 test examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAifCvd_Tth9"
   },
   "source": [
    "##Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg_2bsitTwAq"
   },
   "source": [
    "1. Understand and build the dot product self attention block, which is the key of the attention mechanism.\n",
    "2. Build a transformer from scratch with multiple attention heads.\n",
    "3. Train and evaluate the performance of such neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XFG0NDRu5mYQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed astunparse-1.6.3 cachetools-5.3.3 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.28.1 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.62.0 h5py-3.10.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 nvidia-cublas-cu12-12.2.5.6 nvidia-cuda-cupti-cu12-12.2.142 nvidia-cuda-nvcc-cu12-12.2.140 nvidia-cuda-nvrtc-cu12-12.2.140 nvidia-cuda-runtime-cu12-12.2.140 nvidia-cudnn-cu12-8.9.4.25 nvidia-cufft-cu12-11.0.8.103 nvidia-curand-cu12-10.3.3.141 nvidia-cusolver-cu12-11.5.2.141 nvidia-cusparse-cu12-12.1.2.141 nvidia-nccl-cu12-2.16.5 nvidia-nvjitlink-cu12-12.2.140 oauthlib-3.2.2 opt-einsum-3.3.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.36.0 werkzeug-3.0.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "# ! pip install -q tfds-nightly\n",
    "# ! python3 -m pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4_Qt8W1hJE_"
   },
   "source": [
    "Use [TFDS](https://www.tensorflow.org/datasets) to load the [Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt) from the [TED Talks Open Translation Project](https://www.ted.com/participate/translate).\n",
    "\n",
    "This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8q9t4FmN96eN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 22:05:02.057410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38339 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:3b:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TyTo86x5n1om",
    "outputId": "20e0b4b1-799c-455e-f798-386327263add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Portuguese:\n",
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "\n",
      "> Examples in English:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 22:05:02.682524: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  print('> Examples in Portuguese:')\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "  print()\n",
    "\n",
    "  print('> Examples in English:')\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCEKotqosGfq"
   },
   "source": [
    "Now that you have loaded the dataset, you need to tokenize the text, so that each element is represented as a [token](https://developers.google.com/machine-learning/glossary#token) or token ID (a numeric representation).\n",
    "\n",
    "Tokenization is the process of breaking up text, into \"tokens\". Depending on the tokenizer, these tokens can represent sentence-pieces, words, subwords, or characters. To learn more about tokenization, visit [this guide](https://www.tensorflow.org/text/guide/tokenizers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KVBg5Q8tBk5z"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DYWukNFkGQN",
    "outputId": "0b625c0b-8b80-4985-c887-9ff213b72f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf2ntBxjkqK6",
    "outputId": "0ece37ce-01bb-4029-ced3-19030c740c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "Add a start and end token to the input and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "\n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
    "\n",
    "* Graph tensors do not have a value.\n",
    "* In graph mode you can only use TensorFlow Ops and functions.\n",
    "\n",
    "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "  result_pt.set_shape([None])\n",
    "  result_en.set_shape([None])\n",
    "\n",
    "  return result_pt, result_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JrGp5Gek6Ql"
   },
   "source": [
    "Note: To keep this example small and relatively fast, drop examples with a length of over 20 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2QEgbjntk6Yf"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fXvfYVfQr2n",
    "outputId": "fc3d4bc4-dba8-43fc-f817-b406729541c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 22:07:09.388975: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
       "        [8214,   95,  198, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,  584,   12, ...,    0,    0,    0],\n",
       "        [8214,   59, 1548, ...,    0,    0,    0],\n",
       "        [8214,  118,   34, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   98,   25, ...,    0,    0,    0],\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   18, 2059, ...,    0,    0,    0],\n",
       "        [8087,   16, 1436, ...,    0,    0,    0],\n",
       "        [8087,   15,   57, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDkTVv3KMJX_"
   },
   "source": [
    "We'll start with the **Multi-Head Self-Attention** layer since that's the most involved bit. Once we have that working, the rest should make sense as you go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqX04fFXBdxy"
   },
   "source": [
    "## Multi-Head Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NAf9HP7RsQu"
   },
   "source": [
    "\n",
    "Inside each attention head is a **Scaled Dot Product Self-Attention** operation as we covered in the slides. Given *queries*, *keys*, and *values*, the operation returns a new \"mix\" of the values.\n",
    "\n",
    "$$Attention(Q, K, V) = softmax(\\frac{QK^T)}{\\sqrt{d_k}})V$$\n",
    "\n",
    "The following function implements this and also takes a mask to account for padding and for masking future tokens for decoding (i.e. **look-ahead mask**). We'll cover masking later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7hpO6cGEN7HK"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead)\n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lC_HhsreXh3H"
   },
   "source": [
    "Suppose our *queries*, *keys*, and *values* are each a length of 3 with a dimension of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WB2cDybgX5LZ",
    "outputId": "c9c96a90-73e3-4027-f65c-62ae05476811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries:\n",
      " [[0.02135963 0.82901716 0.67566025 0.26137993]\n",
      " [0.02192516 0.7561811  0.10454049 0.70594394]\n",
      " [0.71585923 0.18293364 0.6464676  0.29505146]]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 3\n",
    "embed_dim = 4\n",
    "\n",
    "queries = np.random.rand(seq_len, embed_dim).astype('float32')\n",
    "keys = np.random.rand(seq_len, embed_dim).astype('float32')\n",
    "values = np.random.rand(seq_len, embed_dim).astype('float32')\n",
    "\n",
    "print(\"Queries:\\n\", queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuNdMuz5vb1c"
   },
   "source": [
    "This would be the self-attention output and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxKj56hNX5UO",
    "outputId": "dbee2e12-0a15-49c5-80cf-82143e015e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      " tf.Tensor(\n",
      "[[0.4285965  0.47079706 0.58973664 0.91121703]\n",
      " [0.4253616  0.43867648 0.5750414  0.9148814 ]\n",
      " [0.4004564  0.47514078 0.5863621  0.9124819 ]], shape=(3, 4), dtype=float32) \n",
      "\n",
      "Weights\n",
      " tf.Tensor(\n",
      "[[0.3517414  0.30134255 0.3469161 ]\n",
      " [0.31148842 0.3212007  0.36731082]\n",
      " [0.36204648 0.33474782 0.3032057 ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output, attn_weights = scaled_dot_product_attention(queries, keys, values)\n",
    "\n",
    "print(\"Output\\n\", output, \"\\n\")\n",
    "print(\"Weights\\n\", attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "5oS1aQOJky-3",
    "outputId": "b638881d-76f8-47fd-e17d-972f245a31d5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAHUCAYAAADx3sYrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACFPElEQVR4nO3dd1hUR9sG8Htp0ovSUVFBwIoIArbYS0SNGGuiqNGYqGgsiUZNPmOMJdEUjdGYaKIGRUXFmgCKvYFgARVEsdIEC73Dfn8Q9nXdBdbDIku4f++11xtm5szMYVd4mJkzIxKLxWIQERER0WtTq+0OEBEREdVVDKSIiIiIBGIgRURERCQQAykiIiIigRhIEREREQnEQIqIiIhIIAZSRERERAIxkCIiIiISiIEUERERkUAMpOg/xdHREePHj5dJT0tLw4IFC/DWW2+hVatWcHR0RGZmZi30ULWNHz8ejo6Otd0NldG7d2/07t272vV8/vnncHR0REJCghJ6RUSqhIEUvTElJSXYs2cPxo0bB3d3d7Rp0wadO3fGkCFDsHjxYoSGhtZY259//jkOHjyITp06Ydq0afD19UWDBg0UujY5OVkSfP3www8Vlvv555/h6OiIsLCwCvtQ279MVaEPiiopKYGbmxvatGmD7OxsmfzU1FQ4OjrC0dER+/btk1vHuHHj4OjoiMuXL9d0d5VOWUEcEdUsjdruANUPJSUl+Oijj3D27FkYGhqiR48esLS0RFFREe7evYsjR47g3r176NOnj9LbLiwsxIULF9ClSxd8//33r319QEAASktLIRKJsH//fsyaNQsaGv/Nfzrffvst8vLyarsbAAB1dXW4u7sjNDQUERER6Nmzp1T+xYsXAQAikQiXLl3Cu+++K5Wfl5eHa9euQVdXFx06dBDUh61btwq6jojqj//mbwNSOUeOHMHZs2fh5OQEPz8/GBgYSOXn5eXh+vXrNdL206dPUVpaCnNz89e+tqSkBPv27YO+vj6GDh2KnTt34sSJE+jfv38N9LT2WVtb13YXpHh6eiI0NBSXLl2SCaQuXboEbW1teHp6yh0FjIyMRFFRETw9PaGpqSmo/aZNmwq6jojqDwZS9EZcvXoVAODt7S0TRAGAjo4OPD095V575MgR7N69GzExMSgoKEDjxo0xZMgQTJkyBVpaWpW227t3byQmJgIAAgMDERgYKOnHqlWrquz3mTNnkJKSglGjRmHs2LHYuXMn9uzZIxNIvdyOj4+PVN7t27el1h29POpmY2ODEydOSL5OT0/Hli1bcPz4cSQmJkJTUxNt27bFhx9+iG7duknVu3//fixcuBArV66EtbU1fvnlF9y4cQMikQhubm5YsGAB7OzsJOUV6cP48eMRHh6O27dvS7VVWlqK3bt3Y+/evbh37x7EYjHs7Ozw7rvvYsyYMVBTk14l4OjoCHd3d6xduxY//vgjTp48ifT0dNja2uKDDz6QGT2qSOfOnQGUBU2vCgsLQ8eOHdGtWzecOnUK9+7dQ4sWLST55deU11Hu7Nmz2L59O6KiopCTkwNLS0v069cP06ZNg6GhoVTZ8qm1l98jAMjKysK6desQHByMFy9ewMbGBqNHj0bfvn3Rt2/fSj9fu3btwo4dO/DgwQMYGBigT58+mD9/vuTfRVhYmNRn6OX37eV6IyIisHnzZty6dQvPnz+HkZERbGxs8NZbb8HX17eS7yoRKRMDKXojjI2NAQAPHjx4resWLlyI/fv3w9LSEv3794ehoSGuXbuGtWvX4uLFi/jzzz8rnWbz8fFBYmIitm/fDicnJ/Tt2xcA0KpVK4Xa3717N4CyX2AODg5o06YNzp8/j8TERNjY2Ei1ExoaivDwcHh7e0vlAYCvry+OHz+O2NhY+Pj4SH5hvxxUJiYmYvz48UhMTISbmxu6d++OvLw8nDx5ElOmTMHXX3+NUaNGyfTx1KlTCA0NRffu3TFmzBjEx8fj9OnTiI6OxtGjR9GwYUOF+1CRzz77DEeOHIGVlRVGjBgBkUiE48ePY+nSpYiMjJQ7ZZqZmYmxY8dCS0sLAwYMQGFhIYKCgrBo0SKoqanB29u7ynZbtmwJU1NTxMbG4sWLFzAxMQEAPHr0CImJiRg9ejQ8PDwAlE31vRxIlU/9vRxIrV+/Hj///DOMjY3Rs2dPNGzYEHFxcfjjjz9w5swZ7N69G/r6+pX2qaCgABMmTMDNmzfRunVrDBkyBFlZWfj1118RERFR6bWrV6/GuXPn0KtXL3Tt2hVhYWHYs2cPHj58iO3btwMoC2x9fX2xbds2AMCECRMk15d/bs+cOYOPPvoI+vr66N27NywsLJCeno579+5h586dDKSI3iQx0Rtw8+ZNcZs2bcSOjo7iTz/9VBwcHCxOSEio9Jp9+/aJHRwcxDNmzBDn5eVJ5a1bt07s4OAg3rp1q1S6g4ODeNy4cVJpjx8/Fjs4OIgXLFjwWn1OSUkRt2rVSty/f39J2l9//SV2cHAQ//jjjzLly/t06dIlufUtWLBA7ODgIH78+LHc/HHjxokdHR3FR44ckUrPyMgQDx06VNyuXTtxWlqaJL38+9OqVSvxhQsXpK5Zs2aN2MHBQfzbb7+9dh8cHByk0g4fPix2cHAQDxs2TJydnS1Jz8nJEXt7e4sdHBzEhw4dkrrGwcFB7ODgIF60aJG4uLhYkn7nzh1xq1atxG+//bbc9uWZO3eu2MHBQfzPP/9I0nbv3i12cHAQX716VVxaWir29PQUz5w5U5KfmZkpbtWqldjd3V1cWloqFovF4osXL4odHBzEo0ePFmdkZEi1Uf69XL58uVR6r169xL169ZJKW79+vdjBwUE8Z84cSd1isViclJQk9vDwkPtZK/++9+jRQ5yYmChJLyoqEr/33ntiBwcH8fXr16tsu5yvr6/YwcFBHBMTI5P37NkzudcQUc3gU3v0RrRu3RrfffcdTE1NcejQIcycORO9e/eGh4cHZsyYITN1AgDbt2+HhoYGVqxYAW1tbam86dOnw9jYGIcPH66xPu/duxclJSUYPny4JG3w4MHQ1NTEvn37UFJSorS2YmNjER4ejv79+8PLy0sqz9DQEDNnzkRBQQGCg4Nlrh00aJDM9FX5yFV0dHS1+1b+RNy8efOgp6cnSdfV1cVnn30GoGxB/qt0dHSwcOFCqKurS9Ls7e3RsWNHxMfHIycnR6H2y6d8X57eu3TpEvT09NC2bVuIRCK4u7sjLCwMYrEYQNn0WElJCTw8PCASiQAAf/31FwBg2bJlMlN4w4cPR6tWrRT6PB04cABqamqYO3eupG4AsLKykho9kmfGjBlS69A0NDQkn6+oqKgq236VvCdPy0cgiejN4NQevTGDBg1Cv379EBYWhsjISMTExCAyMhLHjx/H8ePHMWzYMKxatQoikQh5eXmIjY2FiYmJZIrjVVpaWoiPjxfUl5iYGBw/flwqzcDAABMnTgRQtiZo3759UFNTw7BhwyRljI2N0bt3bwQHB+PUqVNKe8qwfA1ZdnY2fv75Z5n858+fAwDu3bsnk9e2bVuZNCsrKwBARkZGtft269YtqKmpwd3dXSavU6dOUFdXR0xMjEyera2t3GkyS0tLAGVTfy8HZhWRF0iFhYXBzc1NMq3r4eGBoKAgxMbGolWrVnLXR127dg2ampoICgpCUFCQTDtFRUV4/vy51BTiq7Kzs/Ho0SNYWVmhcePGMvmurq6V3ouy3qshQ4YgJCQEo0aNwttvvw1PT0907NhR8r0lojeHgRS9UZqamujWrZtk4XRJSQmCg4OxePFiHDhwAP369UPfvn2RmZkJsViM58+fY/369UrvR0xMjEy9NjY2kkDq7NmzSExMRLdu3WBhYSFVztvbG8HBwdizZ4/SAqn09HQAwPnz53H+/PkKy+Xm5sqkvTq6AkASYJSWlla7b1lZWTAyMpK7sF9DQwMmJiZ49uyZQv16uW+Kjug1adIEjRs3xv379/HkyRNkZGTg6dOnUg8nvLxO6uVAqkuXLpIy6enpKC4urvLzlJubW2kgBQCNGjWSm19Rejl569HKR+xe573q378/Nm3ahD/++AP79++XrOVr06YN5s2bh65duypcFxFVDwMpqlXq6uoYNGgQ4uLisHHjRly6dAl9+/aVjGS0bt1a8qSdMg0fPlxqyu5Ve/bsAQCcO3euwp2+z549i+TkZMmIQnWU/4JdvHixzFN/tc3AwAAZGRkoKiqS2UaguLgYL168qHKBdnV5enpi7969uHjxomRH+vLgCQDs7OxgZmaGS5cu4Z133sGdO3dgbW0NW1tbSRl9fX2IxWKEh4cL7kf5fcoLHCtLrwk9e/ZEz549kZubi+vXr+PUqVPw9/fHRx99hAMHDsDe3v6N9YWoPuMaKVIJ5VM85Wtc9PT00LJlS9y5c0cyWvOmpKWl4dSpU9DX18eIESPkvjp27CjZY6pc+RYAFY0sVJbv7OwMAFU+9VVdVfVRnlatWqG0tFRu3y5fvoySkhK0bt1aaX2Up3yKLiwsDJcuXYKRkZHMk5fu7u6IiIjA2bNnAUBmO40OHTogIyMDd+7cEdwPfX19NGnSBE+ePJG7O3xkZKTgul+lpqam0Kidrq4uOnfujIULF+Kjjz5CUVERzpw5o7R+EFHlGEjRG3HkyBGcP39e7i/wtLQ0yWJlNzc3SfrEiRNRVFSERYsWyT0XLyMjAzdv3lR6X/ft24fi4mIMGTIEy5cvl/sqX8u1d+9eyT2Vb/GQlJQkt97K8tu1awc3NzccO3YMe/fulXv97du3qz3iUVUf5Snf8+n777+X2vU8Ly9Psu3BiBEjqtWvqpQHRRcuXMDly5fRqVMnmb2rPDw8kJOTgy1btgCQ3T+qfNr2yy+/xJMnT2TayM3NxbVr16rsy7Bhw1BaWooffvhBEvgDZUcJVbSeTwhjY2M8f/4c+fn5MnmXL19GcXGxTHr55+PVhzOIqOZwao/eiOvXr2P79u0wMzNDx44dJQt1ExIScPr0aeTn56NPnz4YOHCg5JoRI0bg5s2b2LlzJ/r164du3brBysoKGRkZSEhIwOXLlzF8+HB8/fXXSuunWCyWBHUjR46ssJytrS06deqE8PBwnDlzBj179oSnpyfU1NTwww8/4M6dO5I1QtOnTwdQ9ot9y5Yt+PLLL9G/f3/o6enB0NAQ48aNA1AWqEyYMAGLFy/GX3/9BWdnZxgYGCAlJQVxcXGIi4vD7t27q1yHU5mq+iDPkCFDEBoain/++QdeXl7o27evZB+phIQEDBo0CEOHDhXcJ0WYmppKRigB2dEm4H9TfXFxcXLLdO7cGfPmzcMPP/yAAQMG4K233kLjxo2Rm5uLpKQkXL58GR07dpQEYhWZMmUKjh8/jqNHj+L+/fvo2rUrsrKyEBQUBDc3Nxw/flzqaT6hOnfujOjoaEyZMgVubm7Q0tKCk5MTevfujW+++QZPnjxBx44dYWNjA01NTdy8eROXLl2CjY2NzJOfRFRzGEjRG/HBBx+gWbNmuHDhAm7fvo1z586hsLAQxsbGcHd3x+DBgzFkyBCZX0BLlizBW2+9hV27duHChQuShc9WVlaYPHmy0n+BX7hwAQkJCWjdujXatGlTadlRo0YhPDwcu3fvRs+ePWFnZ4dVq1bhjz/+wM6dO1FQUADgf4FU9+7d8fnnn2PPnj3Ytm0bioqKYGNjIwliLC0tsW/fPvj5+SEkJASHDx9GSUkJTE1NYW9vj3HjxsHBwaFa91dVHyryww8/oFOnTti3b59kYbOdnR0++OADjB07tlp9UpSnp6ckkHp5fVS5Zs2awcLCAk+ePIG9vb3cI4GmTp2Kjh074q+//kJkZCROnDgBfX19WFhYYNSoURg8eHCV/dDW1sb27duxbt06BAUFYevWrWjcuDE++ugjSSCljDVj06ZNQ2ZmJk6ePIkrV66gpKQE3t7e6N27Nz766CMcP34cN27cwMWLFyESiWBtbY2PP/4YEyZMgJGRUbXbJyLFiMQvj00TEZFge/bswZdffomlS5dizJgxtd0dInoDuEaKiOg1yVtjlZSUhA0bNkBDQwO9evWqhV4RUW3g1B4R0WuaNWsWioqK0LZtWxgYGCAxMRGnTp1CXl4e5s2bJ7P3GBH9d3Fqj4joNe3YsQOHDh3CgwcPkJ2dDV1dXbRq1Qrjxo1D//79a7t7RPQGMZAiIiIiEohrpIiIiIgEYiBFREREJBADKSIiIiKB+NQeERGRitFpqryNbvMe+SutLpLFQOoldu/xw0Zl4neOBRBX290gleGA5guO1HYnSIXc/7bqXfCrQyTihFFdwXeKiIiISCCOSBEREakYEcc56gwGUkRERCqGU3t1BwMpIiIiFcNAqu7gO0VEREQkEEekiIiIVIxIJKrtLpCCGEgRERGpHE4Y1RV8p4iIiIgE4ogUERGRiuFi87qDgRQREZGKYSBVd/CdIiIiIhKII1JEREQqhjub1x0MpIiIiFQMp/bqDr5TRERERAJxRIqIiEjFcESq7mAgRUREpGIYSNUdDKSIiIhUjAg8IqauYMhLREREJBBHpIiIiFQMp/bqDgZSREREKoaBVN3Bd4qIiIhIII5IERERqRiOSNUdDKSIiIhUDgOpuoLvFBEREZFAHJEiIiJSMZzaqzsYSBEREakYBlJ1B98pIiIiIoE4IkVERKRiRBznqDMYSBEREakYTu3VHQykiIiIVIxIxEOL6wqGvEREREQCcUSKiIhIxXBqr+5gIEVERKRiuNi87mAgRURERBUKCQnB5s2bERcXB01NTbi6umLu3LlwcHCo8trTp09j165duH37Nl68eAGRSAQbGxsMGDAAPj4+MDQ0lHtdUFAQduzYgZiYGBQWFsLCwgKurq5YtWqVsm+v2hhIERERqRhVmdoLCAjAF198AQcHB3z66acoKCiAn58fxowZA39/fzg6OlZ6/Z07dwAAw4cPh7m5OYqKihAdHY2NGzfi6NGj2LdvH3R1daWuWbp0Kfz9/dGrVy988skn0NbWRnJyMq5evVpj91kdDKSIiIhUjCoEUhkZGVi1ahUsLS3h7+8PfX19AMDbb78NLy8vLF++HNu3b6+0jilTpmDKlCky6XZ2dlizZg1CQkIwbNgwSfqBAwewc+dOLFu2DKNGjVLq/dSU2n+niIiISOWEhoYiOzsbI0eOlARRAGBtbY0BAwYgLCwMycnJguq2sbEBAGRmZkqlb9y4EU5OTpIgKjs7G6WlpQLv4M1gIEVERKRiRFBT2kuo69evAwBcXFxk8srToqOjFaorJycHz58/R0JCAkJCQrBmzRpoamqia9eukjL379/HgwcP4Orqit9++w1dunSBq6srOnToAF9fXyQkJAi+l5rEqT0iIiJVo8SpvT59+lSaHxoaKjf9yZMnAABLS0uZvPK0lJQUhfqwbNkyBAYGSr5u2bIlNmzYADs7O0lafHw8AOCff/5BQUEBPv74YzRv3hxhYWHw8/PD9evXcfDgQTRs2FChNt8UBlJEREQkIy8vDwCgpaUlk1eelp+fr1BdU6ZMwdChQ5Geno4rV64gIiIC6enpUmVycnIAAM+fP8eWLVvQrVs3AEC/fv2gr6+PjRs3YuvWrZg7d67QW6oRDKSIiIhUjDIXm1c04lQVHR0dAEBhYaFMXnmatra2QnXZ29vD3t4eADBo0CAEBwdj1qxZUFdXh5eXl1Rd5ubmkiCq3LvvvouNGzfi0qVLgu6lJnGNFBERkYoRiURKewllYWEBQP70XXmavGk/RfTv3x96enrYtWuXJM3KygoAYGZmJlPe3NwcQNmThKqGgRQREZGKUYXF5u3btwcAufs3Xbt2DQDQrl07QXWXlJSgqKhIKjBycHCAjo6OZG3Wy8qfDmzUqJGg9moSAykiIiKS0bdvX+jp6SEgIADZ2dmS9KSkJAQFBcHd3V0yipSXl4f4+HikpqZK1ZGWlia3bn9/fxQWFqJDhw6SNG1tbbz99tt4+vQpgoKCpMrv2LEDANCzZ08l3JlycY0UERGRilGFDTmNjIwwf/58LFmyBGPHjsXo0aNRWFgIPz8/AMDixYslZaOiouDj4wNvb2+pY1wGDx4MFxcXtG3bFhYWFsjIyEB4eDhOnz4NGxsb+Pr6SrU5Z84cXLhwAZ9++imuXr2KZs2aITw8HH///TdatWqF8ePHv5mbfw0MpIiIiFRNNdY2KdOYMWNgbGyMLVu2YPXq1dDU1ISbmxtmz54NJyenKq/38fHBhQsX4O/vj/T0dGhpacHW1hbTp0/HxIkTYWRkJFXe3Nwce/bswdq1a3HkyBFkZGTA3NwckyZNgq+vr2QBvCoRicVicW13QlXYvedf210gFRG/cyyAuNruBqkMBzRfcKS2O0Eq5P63g2u0fgf3DUqrKy58utLqIlkckSIiIlI1tT+zRwpiIEVERKRqVGRqj6rGmJeIiIhIII5IERERqRqOSNUZDKT+Aywb6mD2iPZ4y9kSxvoNkJaeh2MRiVi3PxqZOUUK1fHhYCd4traAvY0hTAwaoLQUSHqag3M3UvDH37FIeZ4nc03Zgmz5rt55ihFLjgm+J6oZKSlPsXbtDpw9ewXp6ZkwN2+IPn084es7FkZG+grVsXnzfoSFRSE+/jFevMiESCSCjY05unTpgEmThsHS0rSG74Jeh6WRNub0c0APR3MY62oiLbMAIbdSsPb4HWTmKfbzYepbLeBpZ4qW5vow0dNCqViMxBd5OHf3KbacvYeUDNnz1ipbjH310QsM/+W84HuqFzhfVGcwkKrjmprrI2BpP5gaaeNYRALikzLhbNcIk952xFvOVhj11TGkZ8uek/Sqsb3tkZNfjPCYNDzNyIeGugitm5lg8iAnjOrZAu8tO4FbD1/IXJeQlo19Z+7LpKc8y1XK/ZHyPHqUjDFj5uPZs3T06eOBFi0aIyrqDrZvP4SzZyPh7/8dTEwMq6xn9+4g6Opqo1OntmjUyBjFxcWIibmHrVsPYu/eY/jrrxVo3dquynqo5jVtqIt907vC1KABQm6mID41G85NjPFBtxbo4WCOERvPIz236mBqrIctcguLEXb/GZ5mFUJDXYQ21kaY0r0FRnVqgrGbLuJWUqbMdQnPc7E3MkEmPSVD9g8zorqKgVQdt/QDN5gaaWPp1ghsD7kjSV80zgWTBzlh3qj2+PKPiCrrGbjgbxQWlcqkj+5lhxUfumPe6PaY/N1pmfyEtBys23ejejdBb8TSpRvx7Fk6vvhiKsaPHyJJX7lyM7ZuPYgff/wLX389o8p6jhxZjwYNZE+D37MnGF9+uR4//vgXfv/9K2V2nQRa5t0WpgYN8NXBG9h24YEkffHg1pjSvQU+HeCELwKjq6xnwI+nUVgs+/NhjHtTrHy3PT4d4IQP/gyXyU94kYe1x7mNiBBiTu3VGRw8rMOamuvjrfZWeJyajb+O3ZHKW7s3Gjn5RRjWrTl0GqhXWZe8IAoAjl56BABoZmlQ/Q5TrXn0KBnnzl2FjY053n/fSypv5sz3oKurjUOHTiI3V3aK5lXygigAePvtstPaHz5Mqn6HqdqaNtTFWw7mePw8F9svPpDK+ynkNnIKiuHd0QY6mgr8fJATRAHA0aiy97qZqV61+0uvECnxRTWKgVQd5tm67DTsc9EpeHVb1Zz8YkTGPYWutgZc7IWvWenT0QYAEPsoXW6+oa4WRvRogWnvtMa4fi3RwV71DpQkICwsCgDQrZsL1NSk/9nr6+uiY8dWyMsrwPXrtwW3ceJE2YiEo2MzwXWQ8nS2K/u3ePZOmuzPh8ISRD58Dl0tDbg0NRbcRp9WFgCA2GTZaT0AMNTRwEi3Jpjeyx7jO9uiQzXaqnfURMp7UY3i1F4d1sK6bD3L/eQsufkPUrLwVnsrNLMywIWbsqdpyzOqZwtYNtKFXgMNODQ1Rte2FkhIy8bqXdfklm/dzATffuQhlXbrwQvM23gRcY8z5F5Db969e4kAgGbNbOTm29pa49y5q7h/PxGdOzsrVGdAQDBSUp4hNzcPcXEPceHCddjYmGPevInK6jZVQwuzsocH7qflyM1/8DQXbzkAzc30cSH+mUJ1ju7UBJZGOtBroA5HSwN0tTdDwvNcfPdPrNzyra2N8N1I6c/TraQMzN19DbdT5P/cIqprVDqQevLkCaKjo5GSkoK8vDzo6OjA0tIS7dq1g4WFRW13r9YZ6GoCALJy5S8mz/53EamhrvypGHlG9bKDS8v/jWBdj3+GOesv4OGTbJmym4/GIjj8Me6nZKKgsBR21oaYOrQVBnk0hd/i3hiyMAhPXnBRqSrIzi5b/G9goCs3vzw9K0v+L115AgKOSY1gtWvXEt9//ylsba2r0VNSFgPtsh/vWfnyF5OXpxtqK/5rYLR7U7g0NZF8ff1xOj7xv4KHch4u2XwmHv/cSMH9tGwUFJfCzkwfH/e0w6D21tjxoSe81p7Fk8yqp5LrLa6RqjNUMpC6c+cOli9fjrCwMADAy8cBiv79cHl4eGDRokVwcHColT7+V5VvWWCsr4U2zRpi3uj2OLh8AGauO4+zUSlSZVfuuCr1dfT955i59jxEnwBvezTFFC8nLPeTLkP/HXv2rAEAvHiRiVu34vHjj39h+PA5+OmnBejevWMt945qQvmWBca6mmhrY4RPBzjh0KzumLnjCs7EpUmVXX40Rurr6MQMzNhxBRtEIrzdzgofvtUC3xy59cb6XucwjqozVG6N1J07dzBmzBhcv34dw4YNw9KlS7Fp0yZs3boVmzZtwtKlSzFs2DBcv34dY8eORVxc/X0iJOvfESeDCkac9P8dscqsYMSqMunZhTh/IwUTVp5EfmEJvp/WGQ0UWJQKADtD7wIA3FuZv3a7VDP09ctHnORvS1GebmDw+ouGTUwM0bWrC/7442toa2th/vwfkJ9fILyzpBRZ+cUAAANtTbn55emZ/5Z7Hem5RTh35ynGb76EgqISfD+6AxpoKPbrZMelhwAA9+YNX7tdIlWkciNSP/zwA4yMjLBjxw5YWVnJLTNq1CjMnDkT48aNw08//YQNG5R3SnZdcu/ffVuaW8l/oq78SbsHFayhUkRWbhGu3nmK/p2awKGxEaLvP6/ymueZZb9EdRqo3Mer3mrRomxt1IMHiXLzy5+0a95c/hoqRRga6qNDByccP34Jd+48Qrt2LQXXRdV3L61sOr65mfzguJlpWXB9P0122l5RWfnFuPIwHQPaWsLBwgDRiVWvi3yeU/bzQVeLPx8qxUXidYbKjUhFRkZi/PjxFQZR5aytrTFu3DhERFS9R9J/1aVbqQCAbu0sZabT9bQ14Opgitz8Yly9+7Ra7Vg0LPuBW1wq/xHoV7n8++Te41ThP6BJuTw82gMAzp27itJX3sfs7FxcuRIDHZ0GcHZ2rFY7T56ULVrW0FBs9JJqzsV/F5B3b2km+/NBSx2utg2RW1iMqxU8kasoSyNtAEBxqbiKkmU6/LvG6tFzbtpbKZFIeS+qUSoXSBUVFUFLS7HF0Q0aNEBRkWJHHPwXPUrNxpmoZDQx18f4ftJ//X8yoh30tDVx4Nx95BWUSNJbWBughbX0CJZVI100MtSW28bY3nZwtmuEpKc5uP3of39tOjYxhoa67D9QxybGmDu67CmdA+ceCL01UrKmTa3QrZsLEhNTsWPHUam8n3/eidzcfAwd2gu6uv/7HMTHP0Z8/GOpsklJqXj6VHaHewDYtesfREffgZWVKRwcbJV/E/RaHj3PxZm4VDRpqAufzs2k8mb3d4ReAw0EXklEXtFLPx/M9NDilREsa2NtmOrL/5k81qMpnJsYIzE9D7dT/rcFgpOlATTkjKg4WRrg0wFOAIADV2V3PCeqi1RubNXBwQG7d++Gt7c3dHXlP2EEADk5Odi1a1e9X2y+5I8IBCzthyUT3dClrSXuJmaig30jdG5jgXtJmfh+T5RU+WNrys6/snvPX5LWtrkJfp7VDVfvPMXDJ9l4mpEPEwMtdLA3hVNTY2TnFWHehosofWnR/+RBjujd0QYRt9OQ/CwXhUUlaGFtiLecraChroZdJ+7i8IWHb+abQApZsmQaxoyZj2+++Q0XL16HnV0TXL8eh7CwKDRrZoM5c8ZLlR80aDoA4Pbtw5K0W7fi8ckn36JDByc0bWoFU1NjpKdn4dq124iLewBdXR18991cqKtzREoVfBl4A/umd8VX77RFF3tT3E3NRocmxuhib4p7adlYEyy9bUHop70AAM0XHJGktbE2wi/jXHH14Qs8eJaDp9mFMNHVhEtTEzhZGSK7oBjzdl3FywNSk7u3QJ9WFrj84DmS0/NQWFKKFmb66OFgBg11NfiHPcSha9y4tVIcSKozVC6Qmjx5MmbNmoXBgwdjxIgRcHFxgYWFBbS0tFBYWIgnT57g6tWrCAgIQEpKCtauXVvbXa5Vj1KzMWxxMGaPbIe32luhRwcrpL3Ix5//3Fb40OIb919gW9BtuDmZoZeLNYz0tFBQVILHqdnYfCQGW4PikPzKMPyxyATo62jCqakxPFtboIGWGtKzCnH6ejJ2n4hH6BX5a3Go9jRtaoV9+37AunVlhxafORMJMzMT+PgMVfjQ4tat7eDjMwQREbdw+nQEMjKyoKWlhSZNLPDBB8Pg4zMUVlZmb+BuSBGPnudi6M9nMae/I3o4mKGnoznSsvLxx7l7Ch9afDMpA1vP30enZg3R28kCRrqaKCguxeNnufj9TDz+PHcfya8cWhxyMwX62hpwsjREZ7tGaKChjvTcQpy+nYZd4Y9wPEaxfe3qNa6RqjNEYvGre97WvoCAAHz77bfIzs6WbHfwMrFYDD09PcyfPx+jR49WWrsvj9JQ/Ra/cyyA+vtEKL3KQWqUhuj+t4NrtP6WA/9QWl13gj5QWl0kS+VGpABg5MiRGDBgAEJDQ3H9+nWkpKQgPz8f2trasLS0RPv27dG3b18YGlZ9Uj0REVGdwwGpOkMlAykAMDQ0hLe3N7y9vWu7K0RERG+UmE/b1RkqG0gRERHVW1wjVWeo3PYHRERERHUFR6SIiIhUDQek6gwGUkRERKqGa6TqDE7tEREREQnEESkiIiJVw8XmdQYDKSIiIlXDOKrO4NQeERERkUAckSIiIlI1XGxeZzCQIiIiUjUMpOoMBlJERESqhgtv6gy+VUREREQCcUSKiIhI1XBqr85gIEVERKRqGEfVGZzaIyIiIhKII1JEREQqRsydzesMBlJERESqhmuk6gxO7REREREJxBEpIiIiVcMBqTqDgRQREZGq4RqpOoNTe0REREQCcUSKiIhI1ajQYvOQkBBs3rwZcXFx0NTUhKurK+bOnQsHB4cqrz19+jR27dqF27dv48WLFxCJRLCxscGAAQPg4+MDQ0NDqfKff/45AgMD5db1wQcfYMGCBUq5J2ViIEVERKRqVCSOCggIwBdffAEHBwd8+umnKCgogJ+fH8aMGQN/f384OjpWev2dO3cAAMOHD4e5uTmKiooQHR2NjRs34ujRo9i3bx90dXVlrvvuu+9k0uzt7ZVzU0rGQIqIiEjVqMAaqYyMDKxatQqWlpbw9/eHvr4+AODtt9+Gl5cXli9fju3bt1dax5QpUzBlyhSZdDs7O6xZswYhISEYNmyYTP4777yjlHt4E7hGioiIiGSEhoYiOzsbI0eOlARRAGBtbY0BAwYgLCwMycnJguq2sbEBAGRmZsrNF4vFyM7ORklJiaD63yQGUkRERKpGTaS8l0DXr18HALi4uMjkladFR0crVFdOTg6eP3+OhIQEhISEYM2aNdDU1ETXrl3llndzc4OrqyvatWuHUaNG4dixYwLvouZxao+IiEjFiJU4s9enT59K80NDQ+WmP3nyBABgaWkpk1eelpKSolAfli1bJrWIvGXLltiwYQPs7OykyjVq1Ajjx49H27ZtYWBggAcPHsDPzw++vr747LPP5E4T1jYGUkRERCQjLy8PAKClpSWTV56Wn5+vUF1TpkzB0KFDkZ6ejitXriAiIgLp6eky5T777DOZtDFjxsDb2xs//fQTvLy8YGVl9Rp3UfMYSBEREakaJS42r2jEqSo6OjoAgMLCQpm88jRtbW2F6rK3t5c8dTdo0CAEBwdj1qxZUFdXh5eXV6XX6unpYdKkSfjqq69w7tw5jBw58nVuo8ZxjRQREZGqEYmU9xLIwsICgPzpu/I0edN+iujfvz/09PSwa9cuhco3btwYAPDs2TNB7dUkBlJEREQko3379gCAq1evyuRdu3YNANCuXTtBdZeUlKCoqAgZGRkKlX/w4AEAwNTUVFB7NYmBFBERkapRgaf2+vbtCz09PQQEBCA7O1uSnpSUhKCgILi7u0vWK+Xl5SE+Ph6pqalSdaSlpcmt29/fH4WFhejQoYMkLTc3FwUFBTJlnz9/js2bN0NLSwvdu3cXfD81hWukiIiIVI0KDHMYGRlh/vz5WLJkCcaOHYvRo0ejsLAQfn5+AIDFixdLykZFRcHHxwfe3t5YtWqVJH3w4MFwcXFB27ZtYWFhgYyMDISHh+P06dOwsbGBr6+vpOzDhw8xefJk9OnTB7a2tjA0NMT9+/exf/9+ZGRk4Msvv5RMNyrq8uXLsLGxgbW1dYVlkpOTkZCQgE6dOr1W3eUYSBEREZFcY8aMgbGxMbZs2YLVq1dDU1MTbm5umD17NpycnKq83sfHBxcuXIC/vz/S09OhpaUFW1tbTJ8+HRMnToSRkZGkrKmpKbp164bIyEj8888/yMvLg7GxMdzc3DBx4kRBgY6Pjw9mzJghFbC96sCBA1i3bh1iYmJeu36AgRQREZHqUaFDiwcOHIiBAwdWWsbDwwO3b9+WSZ8xYwZmzJihUDtmZmZyz9irDrFYrFAZUTW+3wykiIiIVI0KnLVXXyQlJUFPT0/w9QykiIiIVIxYhUak6pr169dLfR0eHi6TBgClpaVITk7G0aNH4erqKrg9BlJERET0n/Fy0CQSiRAeHo7w8PAKy1tYWGDevHmC22MgRUREpGpU4Km9umr79u0AytY+TZgwAd7e3vD29pYpp6amBhMTEzRv3hxqasK/4QykiIiIVA3XSAnm7u4u+W9vb2/07dtXKk3ZGEgRERHRf9LKlStrvA0GUkRERKqGi82VLi8vD5mZmSgpKZGbX9mmnZVhIEVERKRqOLWnNAcOHMDmzZsRHx9fYRmRSIRbt24Jqp+BFBEREf0n7d+/H4sWLYK6ujrc3NxgaWkJDQ3lhj4MpIiIiFQNB6SU4o8//oCRkRF27twJOzu7GmlDUCCVkZGBtLQ0NG3aFFpaWpL0ffv24fjx49DV1cWECRPQvn17pXWUiIiovhBzak8pHj58CG9v7xoLogCBgdQPP/yAQ4cO4eLFi5K0v/76CytWrJCca3P8+HHs27cP9vb2yukpERER0WswMjKSGvCpCYJ2oLpy5Qo6d+4MbW1tSdoff/wBCwsL+Pn54aeffgIA/Pnnn0rpJBERUb2iJlLeqx7r1asXwsPDFTq8WChBgVRqaioaN24s+fru3btITk7GuHHj4ObmhoEDB6JXr16IiIhQWkeJiIjqDZFIea96bO7cuSgsLMSSJUuQk5NTI20ImtrLz89HgwYNJF9fuXIFIpEIXbp0kaQ1bdoUp06dqnYHiYiI6h0eESOIj4+PTJqOjg4CAgJw+PBhNGvWDAYGBjJlRCIRtm3bJqhNQYGUhYUF7t27J/n63Llz0NfXh5OTkyQtIyNDKtgiIiIiqkmVHU6cl5eHmJgYuXmiaozcCQqkPDw8EBgYCD8/PzRo0AAnTpxA//79pQ79e/z4MaysrAR3jIiIqN6q51NyQsXGxr7xNgUFUlOnTkVISAiWL18OsVgMXV1d+Pr6SvKzs7MRGRmJ4cOHK62jRERE9UY9XyRel4jEApeyp6WlITg4GADQu3dvqTNqbt68iYMHD2Lw4MHcS4qIiOg1NVsarLS6HiwZoLS6SJbgQOq/KCn3cG13gVSEte4Q7LkXVNvdIBUxqsVA6DQdW9vdIBWS98i/RutvtixEaXU9+LK/0uqqay5fvlxlGZFIBH19fTRr1kxqWydF8YgYIiIiFSPmGimlGD9+vMILydXV1dGtWzfMnz8fLVq0ULgNwYFUUVERQkNDERUVhczMTJSUlMiUEYlEWLFihdAmiIiIiASbMWMGoqOjcebMGTRr1gwuLi4wNTXF06dPcfXqVTx48AA9evRA48aNcfPmTZw6dQpXr17F3r170aRJE4XaEBRIPXnyBB988AHu3btX6W6hDKSIiIgE4D5SStG9e3f8/vvvWLp0KUaNGiU1OiUWi7Fr1y6sWrUK27dvx5dffon9+/dj0aJF2LRpE7755huF2hAUSH377beIj4+Hl5cXRo0aBSsrK6irqwupioiIiF7FqT2lWLt2Lbp27YrRo0fL5IlEIowdOxanT5/GunXrsGXLFgwfPhz79u3DhQsXFG5DUCB1/vx5dOrUCd9//72Qy4mIiIhqXFRUFMaNG1dpGUdHR/j5+Um+btWqFaKiohRuQ1AgVVBQwG0NiIiIagr3kVIKsViMhISESss8fvxY6msNDQ1oaWkp3IagWdiWLVsiKSlJyKVERERUFTWR8l71WIcOHRAcHIxz587JzT9z5gxCQkLQoUMHSdrDhw9hamqqcBuCRqQmT56MBQsW4O7du7C3txdSBREREVWkfsc/SjN79myMGzcOH374ITw9PdGxY0c0atQIz549Q2RkJMLCwqClpYVPPvkEAJCVlYULFy5g6NChCrchKJBq1KgRevXqhTFjxsDHxwdt2rSBoaGh3LKdOnUS0gQRERFRtbRv3x5btmzB4sWLcfHiRVy8eBEikUiy40DTpk3xzTffSJYraWpqIjAwsOZHpMo3uBKLxdiwYUOlm11VdNIyERERySeu51NyytSpUycEBwfjypUriImJQVZWFvT19dGqVSu4urpKxTDa2tqvtRknIDCQmjFjhsI7hRIREdFr4u9YpRKJRHB1dYWrq6vS6xYUSM2cOVPZ/SAiIiKqc3jWHhERkarh1J4g69evh0gkwvvvvw9jY2OsX79eoetEIhFmzJghqM1qBVJFRUW4ePEi7t27h5ycHEknCgoKkJ2dDRMTE6ipcZ97IiKi18I4SpDyQGrQoEGqH0idOXMGixcvxtOnTyEWi6U6ERMTg7Fjx2L16tUYPHiw0CaIiIiIFLZ9+3YAgLW1tdTXNUlQIBUdHY0ZM2bAxMQECxcuRFRUFI4ePSrJ79ChAxo3boxjx44xkCIiInpNnMwRxt3dvdKva4KgQGrDhg3Q0dHBvn37YGZmJnforF27drh582a1O0hERFTf8KG9ukNQIHXlyhX06dMHZmZmFZaxtLTEqVOnhPaLiIiISCliY2Nx5MgRxMfHIy8vD1u3bgUAJCQkICoqCl27doWRkZGgugUFUrm5uTAxMam0TH5+vmTnUCIiIlIcR6SUZ+3atdi0aRNKS0sBQGofTLFYjHnz5mHRokUYP368oPoFzcJaWFjg7t27lZaJiYlB48aNBXWKiIioPhOJREp71WdHjx7Fxo0b0aVLFxw4cAAfffSRVH6TJk3Qtm1bnDhxQnAbggKpt956C+fOnUNERITc/NOnT+Pq1avo1auX4I4RERHVVyKR8l712V9//QVbW1ts2LABTk5O0NTUlCljZ2eHhw8fCm5D0NTeRx99hKNHj2Ly5MkYN24cEhMTAQCnTp3C5cuXsXPnTpiZmWHixImCO0ZERERUHbdv38bw4cOhpaVVYRlzc3M8ffpUcBuCAikLCwv88ccfmD17NrZs2SJJnzZtGsRiMZo2bYqff/4ZDRs2FNwxIiKi+kqVRpJCQkKwefNmxMXFQVNTE66urpg7dy4cHByqvPb06dPYtWsXbt++jRcvXkAkEsHGxgYDBgyAj48PDA0NK71+x44d+PrrryV1WVpavnb/q5refPr0KRo0aPDa9ZYTvCFnmzZtEBQUhFOnTuHatWtIT0+Hvr4+OnTogD59+kBDg6fPEBERCSFSkX2kAgIC8MUXX8DBwQGffvopCgoK4OfnhzFjxsDf3x+Ojo6VXn/nzh0AwPDhw2Fubo6ioiJER0dj48aNOHr0KPbt2wddXV251yYlJWHNmjXQ1dVFbm6uoP7b2tri6tWrFeaXlpYiMjIS9vb2guoHBAZSsbGxcHJygrq6Ovr06YM+ffrILRcQEICRI0cK7hwRERHVjoyMDKxatQqWlpbw9/eHvr4+AODtt9+Gl5cXli9fXuXO4VOmTMGUKVNk0u3s7LBmzRqEhIRg2LBhcq/9v//7P7Ro0QItWrTAoUOHBN3D22+/jZ9++gl//PEHPvjgA5n8X3/9FY8ePYKPj4+g+gGBi82nTp2KlJSUSsscOHAAX331lZDqiYiI6jVVWGweGhqK7OxsjBw5UhJEAWXHrwwYMABhYWFITk4WVLeNjQ0AIDMzU27+gQMHcOHCBSxbtgzq6uqC2gCACRMmwMnJCatXr8bIkSNx5swZAMC3336LkSNH4ueff4azszNGjx4tuA1BgVROTg6mTJlS4Tfgn3/+weLFi2Frayu4Y0RERPWVmkh5L6GuX78OAHBxcZHJK0+Ljo5WqK6cnBw8f/4cCQkJCAkJwZo1a6CpqYmuXbvKlH369ClWrlyJCRMmoHXr1sJvAIC2tja2b9+Od955B7du3UJUVBTEYjH+/PNP3Lx5E0OHDsXmzZurtRxJ0JXr16/H1KlTMWPGDGzZskVqNfzx48fx2WefwcbGRrJzKBEREdWOipbflAsNDZWb/uTJEwCQu8C7PK2q2alyy5YtQ2BgoOTrli1bYsOGDbCzs5Mp+/XXX0NfXx+zZs1SqO6qGBgYYNWqVfj8888RHR2N9PR0GBgYoH379kp5KE5QINW5c2csX74cCxYswGeffYa1a9cCKFtRP2fOHJibm2Pbtm0wNzevdgeJiIjqG1V4ai8vLw8A5G4dUJ6Wn5+vUF1TpkzB0KFDkZ6ejitXriAiIgLp6eky5Y4dO4bg4GBs2bIFOjo6gvrdr18/dOnSBZ6envD09JScxGJsbIzu3bsLqrMygseyhg4dipSUFPzwww9YsWIFevXqhVmzZsHExATbtm2DlZWVMvtJRERUbygzkKpoxKkq5YFMYWGhTF55mra2tkJ12dvbS56MGzRoEIKDgzFr1iyoq6vDy8sLQNl6qaVLl2LIkCHo1q2boD4DwOPHj7F7927s2bMHIpEIDg4O6Ny5Mzw9PdGpU6cKnxIUqlp7FJQvOt++fTt27twJQ0ND/Pnnn2jSpImy+kdERES1wMLCAkDZ9N2rU3DlU3pC9nUCgP79+0NPTw+7du2SBFLr1q1DVlYW3n//famdxnNycgCUHTBcUFCApk2bVro31PHjx3Hx4kVcunQJYWFhiI2NRWxsLLZu3Qp1dXU4OztLAqsOHTpUe7umam/29OWXXyI1NRURERHYunWr3PlOIiIiUpwqnJHXvn177Nq1C1evXpVZFH7t2jUAQLt27QTVXVJSgqKiImRkZEjSkpKSkJ+fjzFjxsi95v333wcAREVFVbqBZuPGjTFy5EjJ9kt3797FpUuXcOnSJVy+fBmRkZGIjIzEL7/8Am1tbbi5uaFLly6YNGmSoHtRKJBycnJS6E195513pL4WiUS4deuWoI4RERHVV6qwIWffvn2xfPlyBAQEYOLEiZItEJKSkhAUFAR3d3fJMp68vDwkJSXBwMBAan10WloazMzMZOr29/dHYWEhOnToIEn78MMPMXToUJmyO3bsQHh4OL7++msYGRnJPS+vMuXTiuPGjYNYLMbNmzclgVVkZCTOnj2L8+fP12wg1alTJ0GVExER0etTgQEpGBkZYf78+ViyZAnGjh2L0aNHo7CwEH5+fgCAxYsXS8pGRUXBx8cH3t7eWLVqlSR98ODBcHFxQdu2bWFhYYGMjAyEh4fj9OnTsLGxga+vr6SsvG0WgLJzfAGgR48egqcSy4lEIjRu3BhNmjRBYmIiHj58iMePH0MsFguuU6FA6q+//hLcABEREdVNY8aMgbGxMbZs2YLVq1dDU1MTbm5umD17NpycnKq83sfHBxcuXIC/vz/S09OhpaUFW1tbTJ8+HRMnToSRkVGN30Nubi4uX74sGYW6ffs2xGIx1NXV0bZtWwwaNAienp6C6xeJqxOG/cck5R6u7S6QirDWHYI994JquxukIka1GAidpmNruxukQvIe+ddo/c5+Z5VW1/Vxyn/kX5UVFhbiypUrksDpxo0bKCkpgZqaGtq0aQN3d3d4eHjA1dVVKU/wVXuxeVFREe7du4esrCzo6+vDzs7utecviYiI6H9UYWqvrurUqRMKCwuhpqYGR0dHjB8/Hp6ennB1dZU66kZZBAdS2dnZ+O6773Do0CEUFBRI0hs0aIChQ4fi008/haGhoVI6SURERKSIgoICqKmpoU+fPujfvz88PT1hampaY+0JCqSys7MxduxY3LlzB3p6enBzc4OZmRnS0tIQExODPXv24MqVK9i1a1eNRH9ERET/ZdU5I6++mzNnDi5duoQzZ87g2LFjAIDmzZvD09MTHh4e8PDwgLGxsdLaExRIbdq0CXfu3MHYsWMxZ84cqZGnrKws/PTTT9ixYwc2bdqEefPmKa2zRERE9QGn9oT76KOP8NFHH6GwsBBXr17FxYsXERYWhj179mDnzp1QU1NDy5YtJYGVu7t7tQZ9BC02HzBgAExMTLBr164Ky4wZMwYvXrxAcHCw4M69aVxsTuW42JxexsXm9KqaXmzu6q+8xeaRY+vXYvOKvPz0XvmO52KxGGpqamjdujUCAgIE1StoRCopKQkDBgyotIy7uzu2bt0qpHoiIqJ6jSNSyqerq4sePXqgR48eKCoqwqlTp/Dzzz8jLi4ON27cEFyvoEBKV1cXz549q7TM8+fPBZ/cTEREVJ+JuEhKqcRiMW7cuCHZEuHKlSvIz8+XbMRZnYfjBAVSbdu2RVBQED788EM0a9ZMJv/Ro0f4559/pLZ+JyIiInpT7ty5g0uXLuHixYuIiIhAVlYWgLKgSkdHB126dIGnpyc6d+6MNm3aCG5H4UBq/fr18PDwQKdOnTBlyhR88MEHGDFiBMaNGwcPDw+Ym5sjLS0N4eHh8PPzQ25uLiZPniy4Y0RERPUVp/aEmzt3LsLDwyUzZ2KxGBoaGujYsaMkcHJ2dlbanpevFUgBZRtdde7cGUuWLMHy5cuxadMmbNq0SVKuvMNffvklunTpopROEhER1ScMpIT7+++/oaamhlatWsHT0xOenp7o1KlTjS03Erwh55gxY/DWW2/h4MGDiImJQVZWFgwMDNCqVSsMHToUNjY2yuwnERFRvcFASrh169bBw8PjjZzjB1TziBhra2tMmzZNWX0hIiIiqpb+/fu/0faqfdYeERERKRcf2qs7XiuQSkxMxOXLl1+rgU6dOr1WeSIiovqOU3t1x2sFUgcOHMCBAwcULi8SiXDr1q3X7RMRERFRnfBagZSVlRUXkRMREdUwkVpt94AU9VqB1PDhw+Hr61tTfSGB0p6k44+Nwbh8/jYyM3LQ0NQQ3Xq1xYSP+sHAUFehOnZtO4lrl+Px4N4TZKTnQE1NBAsrE7h6OGDU+LdgZmEsc83RwDDE3nyMu7cTcf9uCgryizBuSh9MnvG2ku+QXkdGWjpO/PU37kTGIDczBwYNjdCqczv0en8gdAwU+zyc2xuKe9fvIO3RE+RmZkMkEsHIoiHsXRzRxbsXjMyMpcpnPk3HrfNRiIu4hbRHT5D1PANaOg1gbd8Ynby6oU1X5xq4U1KEjWVDfDlvJPr3dEZDY32kpKbjcEgElv+0D+kZOQrVMeejwXirc2u0atkYjRoaoLS0FI8Sn+LE2Wis+/1vJKY8lyq/eM67+GLOiErrvPfwCdp0ny30tv7zOLVXd3CxeR2X+PgpZk5cjxfPs9G1Zxs0bWaO2JuPsG/nWYRfiMXPf/rCyFivynoO77sEHZ0GcHZtAZNGBigpLsGd2ETs3XEG/xwMx4+/T0NLJ+nRyI0/HEZOdj4MDHXQyMwQSY8rPzaIat7zpKf4bd6PyEnPhlPndjBrbI6EuEe4ePA07kTG4MPvZ0PXsOrPw+W/L0BLpwGatbODvknZ5yE5PhEXAk8hMvgSPvh2JqztG0vKXzp0BmcDQmFi2QjNne2hb2KI9NTniDkfhfirceji3RNvT/WuwTsneZrbmuPk/q9hYWaEw8GXcTs+CW7O9vCd/Db69WiP3sO/wvP07Crrmfx+H2Tn5ONsWAxSn2ZAU0Mdzm2aYdaHXpgwuhcGjF6G6zcfSMqfuXgL32Cv3LoG9e2Iju1aIOTkNeXcJFEtYyBVx/20cj9ePM/GzPnDMHxsN0n6L2sOYe+OM9iy/h/M/aLyvwwB4M+AT6HVQHaX1yP7L+H7ZXuxZf0/WLV+ilTe/60ah6bNzWFp3RBBhy7j2yW7q39DVC2HfwlATno2vD5+F57vvCVJ/+e3QFwIPIXj245g6MzRVdbj++vn0NSS/TxE/HMBB9ftxvFtR+Cz7GNJuo2jLT74diaat7eXKp/6KAW/zfkRFwJPoX0vN9i0bFKNu6PXtfabD2BhZoS5/7cVG7cGS9K//XIcZn3oha/mj8asRVuqrMe133wUFBTJpE8a2xsbvv0QX302Ct4Tv5Okn70Ug7OXYmTKq6mJMHF0LwDAlp0nhNxSvSHikFSdwVnYOizx8VNEXIyDpbUJho2W3kV+0rT+0NbRwrGjkcjLK6iyLnlBFAD07Fc2JZPw6KlMnntXJ1haNxTQc6oJz5Oe4u6VWBhbNIT7kG5Seb3HvQ0tbS1cC41AYX7Vnwd5QRQAtH3LBQDwLClNKr1NV2eZIAoAzJtaot2/1zyIuqPQfZByNLc1R78eznjwKBW/bguRylv2w15k5+TjveHdoKvToMq65AVRALDvyEUAgH1zS4X6NLC3CxpbN0JYZBxuxD5S6Jr6SiRS3qu+S09Px5YtW/DJJ59g0qRJ8PHxkXlNmDBBcP0Kj0hZW1tX63RkUr5rl+MBAG6dHaGmJh0T6+ppo22HZoi4GIdbUY/g6tFSUBsXz5Q9ddmipVX1Oks17t6/gYp9RyeZz0MDXW00bd0Cd6/E4nHMA9i5OApqIzbsBgDAsrm1wteoaaiX/b86/257k3p0LjuE9fjZKMkJ9+Wyc/JxMeI2+vVwhntHe5w6f1NQG4P6ugIAbsQoFhR98F5vAByNojcnPj4ePj4+eP78ucy/g5dVZwRQ4UDqxAl+8FXN44epAIAmTU3l5jduaoqIi3FIeJimcCB1dH8Y0lLTkZdbiHt3k3El7A4srEwwddYgpfWbasbThLLPg6mNmdz8RjZmuHslFs8S0xQOpCKCLiLzaToK8wrw5EEy4q/dhrF5Q/SfNESh6/Nz8nHr/HWIRCLYdXRS7EZIKRxalP3xc/deitz8+Psp6NfDGS2bWykcSE0c0ws2Vg2hr6uNNk5N0LtbOzx8nIYvVu2q8loby4YY0LMD0jNysPfwRcVvpJ7iSJJyfPfdd3j27BmmTp2KUaNGwcrKCurq6kptg2uk6rDs7HwAgJ6+/IMYy9Ozs/IUrvPogTDERP/vr0unNk3wxYr3YVNBsEaqoyCn7H1uoCf/89BAVxsAkJej+OchMugiEm4/lHxt49AUIxf4oJG1/GDtZWKxGAfW+iP7RRbcB3eDeVPFpn9IOQz/fWI3IytXbn55upFR1Q8flJs0phfcO/7vj7KIa3cxYeZ63Hv4pMprJ4zpBQ0NdewKPIe8/EKF26yvGEgpR0REBHr27Im5c+fWWBt1fqx948aNaN26dW134z9jw/ZZOHl1DQ6cXIrVG6cCAD56/yeEX7hdyz2j2vDRT3Ox7J+1WLh7BSYsLztXc+PMNbgTKbuQ+FVBvx/AzbPXYNvWDm9/yCf2/gt6DPs/6DQdC5v2H8Lr/RUAgAtHV6DvW+0rvU4kEmHi6J4AgM07Qmu6m/8JaiLlveozsVgMOzu7Gm2jzgdSACqd9/wv09cvG2HIyZY/wlCerm8gf4SiMkbGenDzdMDqjVOh1UATK7/YiYJ8+QtOSTWUj0QVVDDiVJBbNoKpU8GIVWV0DfVg39EJE5ZPg2YDTexb7YeigopHFYK3HMSFwFNo1tYO47/+CBpaHPx+0zIz/x1xqmDvsPL0DAX3knrZ8/RsnDgbjcHjViIvvxBbfpoO7QoeWAGAAb06oImNKcIi43Dz9uPXbo9IqDZt2uD+/fs12sZ/IpCqr5rYmgMAHst5og7435N2jW2rnoapiL6BDtq0t0X6ixw8iJe/1oJUg2njss/D08Q0ufnP/k1vVMEaKkXo6OuiiVMz5GRkI/Wh/M/D35v249zeE2ju3BLjl32MBgo8FUbKF3cvGQBg30L+lKrdv0/a3bmfLLiNjMxchF+5A3NTI7R2rHhri/JF5hyNUhxHpJRjxowZOHPmDMLCwmqsDZX8M7Ft27YKl62vo1EA0KFT2XBlxMXbKC0tlXpSKzcnHzeuPYC2tiZat29arXaepmYAANQ1GHershbty9au3L0SK/N5KMjNx6Nb96DZQAtNWjWrVjuZz8o+D68+hScWi3Fkw16EHzkHOxdHvL9kCjQbaFWrLRLu9MWyBeR9u7eHSCSS+lmpr6eNzm6OyMnNR/iVu9Vqx9rSBABQXFwiN9/KwgRv93bhIvPXpCaqv7/blCklJQW9e/fG5MmT4eXlhTZt2lS4A8GwYcMEtSEokLp8+TJsbGxgbV3xI9DJyclISEhAp06dXrv+kpISNGrUCM2bN6+ybFJSEpKSkl67jf8CmyamcOvsgIiLcTiw+4LUhpx/bgxBfl4hhrzrCZ2XRgQe3S97sqtpc3NJ2pPkF9DU0kDDRgYybRzaexGxNx/D3NIYze25BYIqa2htCvuOTrh7JRbhh89Jbch5wu8fFOYXotOgLtDS/t/nIe1x2SJhsyYWkrT01OfQ0NSAvonsD5vLf59HYtwjGJkZw6LZ//79i8ViHFy3G5FBF9HSrRXGfjm5wr2o6M24/zAVx05fR78ezvh4Qn+pDTm/nDsC+nra+N3vOHJf2mfOwa7sPY2L/9/P1CbWjVBQWIzUpxkybUx+vw/cOtjjceLTCveFmjC6JzQ01OG//xzyK9iPiqimfP7555I/JA4ePIiDBw/KbHUgFoshEonebCDl4+ODGTNmVHru3oEDB7Bu3TrExFS9KPVVTZs2hZWVFbZu3Vpl2Y0bN2LdunWv3cZ/xeyFwzFz4nr8/N0BXAm/A9vmFoi58RBXL8ejia0ZJvtKn3s3YXjZ7sMnr66RpN2JTcRX87ejTTtbWDc1RcOGBsjIyEFM9CPcu5MMHd0GWLhsLNRfGYE4uj8M0dfK5p4TH5dNI144fQtpT8p+4DZtZo73PuhdY/dOsobMGInf5v2Io7/uQ/z1OJg1sUDC7Ye4f/0OGtmYo++EwVLl100tWzC87J+1krSkuwnYveJPNGnVHI2sTKFnYoC8zBw8jn2AJw+SoaXTAO9+Ol5qROrkziBEBl2EZgNNWNnZ4Oye4zJ9s2xhg9ZdKl+UTMr1yRd/4OT+r/HD1xPRq2sbxN5NQqcO9ujZtQ3i4pPw1XfSpxFcP/k9AECn6VhJWoe2zbFj4ycIu3IH8Q+eIPVpBhqa6MPdpSXatWqKrOw8fDB7A0pLZUdQyhaZl+9kzmm911Hfp+SUZeXKlTXehqBASpHptPIIT4jWrVvjwoULgq6tb2yamOLXHbPx58YghF+4jbBzsWhkaoB33+uu8KHFLZ1s8O7Y7oi6eg9hZ2OQmZkLLS1NWNk0xKjxPfDue91hbmksc130tfsIPhwhlXbvTjLu3Slbc+Hs2oKB1BvW0NoU09Z9itC//sadiFjcuXwL+g0N0fmdHgofWmxt3xid3+mBhzfv4fblm8jLyoWGliZMLBuh6/Be6DysB4zMTKSuSf/30NqigiKc2S0bRAGAS193BlJv2P2Hqeg2eBG+nDcS/Xo6Y0AvF6SkvsD6Lf8ofGjxtRv38csfQejq7oSBvV3Q0FgP+QVFuP8oFT9tOoJf/vgHCcnP5V7br0d72DYx4yJzAbiQQjm8vWv+iWGRWMAiIycnJ/j6+lY6IvXFF18gODgYly9ffu1O/fbbb/jhhx9w7NgxNGlS+dlcBw8exN69e/HXX3+9djuvSso9XO066L/BWncI9twLqu1ukIoY1WKg1CgNUd4j/xqt3yvknNLqOtq/W9WFSDCFR6TWr18v9XV4eLhMGgCUlpYiOTkZR48ehaurq6BOTZ06FVOnTlWo7DvvvIN33nlHUDtERESqiIvNlSsvLw8hISGIiYlBZmYmDAwM0Lp1a/Tr1w+6ulWP1FdGUCAlEokQHh6O8PDwCstbWFhg3rx51eocERFRfcQ1Uspz+vRpLFiwABkZGVJLk0QiEVauXImVK1eiV69egutXOJDavn07gLK1TxMmTIC3t7fcuUc1NTWYmJigefPmMgenEhEREb0pN2/ehK+vL0pLSzFkyBB4enrCzMwMaWlpuHTpEo4ePYpZs2bB39//tbZeepnCgZS7u7vkv729vdG3b1+pNCIiIlIODkMox6+//gqRSIQdO3agQ4cOUnnDhw/H+++/j/Hjx2PTpk34+eefBbUh6Km9N/E4IRERUX3FqT3liIiIwMCBA2WCqHLOzs4YMGAAzp0TvrhfJXc2JyIiqs9EXGyuFFlZWbCyqnwzaWtra2RnZwtuQ1Ag5eTkpNAeUSKRCLdu3RLSBBEREVG1mJubIyoqqtIyN27cgJmZ8DNIBQVSFR37kpWVhQcPHiA/Px9OTk4wMJA9coSIiIgqx6k95ejRowd27dqF3377DZMnT4a6urokr7S0FFu3bsWFCxcwZswYwW0ICqQq2/wyOzsbK1euxNWrV+XuM0VERESV42Jz5Zg+fTqOHz+OH3/8Ebt27YKbmxvMzMzw9OlTREZGIjExEaamppg2bZrgNpT+Xunr62PZsmVQV1fHjz/+qOzqiYiIiBRiZmYGf39/dOnSBUlJSTh06BC2bNmCgwcPIiEhAV26dMHOnTthbm4uuI0aWWyupqYGDw8PBAUF4auvvqqJJoiIiP6zuLO58jRu3BhbtmzBkydPcOvWLWRlZUl2NrewsKh2/TX21F5hYSEyMzNrqnoiIqL/LFVaIxUSEoLNmzcjLi4OmpqacHV1xdy5c+Hg4FDltadPn8auXbtw+/ZtvHjxAiKRCDY2NhgwYAB8fHxgaGgoVX7r1q04ceIE7t27h4yMDOjr68PW1hYjR47EsGHDpNY4vS4LCwulBE6vqpFAKj4+HkFBQbC1ta2J6omIiOgNCAgIwBdffAEHBwd8+umnKCgogJ+fH8aMGQN/f384OjpWev2dO3cAlG1+aW5ujqKiIkRHR2Pjxo04evQo9u3bJ3XWXXR0NCwtLdG9e3eYmJggOzsbp06dwqJFi3Dp0iWsXr26Ru9XCJH45YNnFLRw4UK56SUlJUhOTsbVq1dRUlKCb775Bu+++261O/mmJOUeru0ukIqw1h2CPfeCarsbpCJGtRgInaZja7sbpELyHvnXaP0+p08rra7tPXoIui4jIwO9e/eGvr4+jh49Cn19fQBAUlISvLy80K5dO8nxca/r999/x5o1a/Dtt99i2LBhVZb/8MMPcebMGZw8eRLW1tYVllu4cCFEIhHmzp0LU1PTCuOVV4lEIqxYsULR7ksRNCIVGBhYaX6LFi0wefLkOhVEERERqQpVmNoLDQ1FdnY2Jk2aJAmigLINLAcMGIDAwEAkJydXueGlPDY2NgCg8BKgl8tXFkgFBgZCJBLhww8/hKmpaZXxSrk3HkiFhobKTVdTU4OhoSH09PQEdYaIiIhUw/Xr1wEALi4uMnkuLi4IDAxEdHS0QoFUTk4OCgoKkJubi1u3bmHNmjXQ1NRE165d5ZbPyMhASUkJMjIycO7cOezbtw9NmjSBnZ1dpe2Uxyfla6EqileUSVAgVR4ZEhERkfIp86m9Pn36VJpfUbDx5MkTAIClpaVMXnlaSkqKQn1YtmyZ1OhQy5YtsWHDhgoDI29vbyQmJgIoGy3q0qULlixZAk1NzUrbeTU+eRPxCs/aIyIiUjGqMLWXl5cHANDS0pLJK0/Lz89XqK4pU6Zg6NChSE9Px5UrVxAREYH09PQKy69evRr5+flITU1FaGgoMjIykJWV9dr3sH79enh4eFR4IgtQdrDxpUuX4Ovr+9r1A9UMpA4dOoR9+/YhJiYG2dnZ0NfXR+vWrTF8+HAMHTq0OlUTERHVW8rcLVvo9JaOjg6Asu2MXlWepq2trVBd9vb2sLe3BwAMGjQIwcHBmDVrFtTV1eHl5SVT3tXVVfLf3t7eWLZsGcaNG4fDhw+jSZMmCt9D+QkrlQVSly9fxi+//CI4kBL0XhUVFWHatGlYsGABwsLCkJOTg4YNGyInJweXLl3CggULMG3aNBQVFQnqFBEREdWu8nVG8qbvytPkTfspon///tDT08OuXbsUKj9s2DDk5eXhwIEDgtqrTHFxMdTUhIeugq7ctGkTTp48CWdnZ2zfvh1RUVE4d+4coqKisG3bNrRv3x6nTp3C77//LrhjRERE9ZWaSKy0l1Dt27cHAFy9elUm79q1awCAdu3aCaq7pKQERUVFyMjIUKh8QUEBAChc/nXcvHkTJiYmgq8XNLV38OBB2NraYvv27VJzp+rq6vDw8MBff/2FwYMHIzAwENOnTxfcOSIiovpIFdZI9e3bF8uXL0dAQAAmTpwotY9UUFAQ3N3dJU/s5eXlISkpCQYGBlLn1qWlpcHMzEymbn9/fxQWFqJDhw6StNzcXIjFYpkn/8VisWS/KnlPEL7Kx8dH6uvAwECEh4fLlCstLUVycrJkXyyhBAVSKSkpGDdunNwFaEDZIrQ+ffpgx44dgjtGREREtcfIyAjz58/HkiVLMHbsWIwePRqFhYXw8/MDACxevFhSNioqCj4+PvD29saqVask6YMHD4aLiwvatm0LCwsLZGRkIDw8HKdPn4aNjY3UuqSHDx9i3Lhx6N+/P5o3bw4TExOkpqYiKCgIcXFx6N69O95+++0q+/1y0CQSiZCYmCh5AvBlampqMDY2xqBBg7Bo0SJB3yNAYCBlbm6O4uLiSssUFRVV6zRlIiKi+koVRqQAYMyYMTA2NsaWLVuwevVqaGpqws3NDbNnz4aTk1OV1/v4+ODChQvw9/dHeno6tLS0YGtri+nTp2PixIkwMjKSlLWwsMCwYcMQGRkp2QzUwMAADg4O+PrrrzFixAiF1jLFxsZK/tvJyQm+vr6CF5IrQtARMT/++CMCAwPx999/S+12Wi4zMxNeXl4YMWIEPvnkE6V09E3gETFUjkfE0Mt4RAy9qqaPiJl18aTS6lrXuZfS6qprAgMD0apVK4WCPqEELTafMWMG2rZtixEjRuDw4cNISUlBUVERUlJScOjQIYwaNQrt27fn+igiIiKqNd7e3jUaRAECp/acnZ0BlC0Amz9/vky+WCzGw4cPJSv+y4lEIty6dUtIk0RERPWGMnc2J+DZs2e4ceMGMjIyUFpaKreMIocnyyMokHJzcxPUGBEREVVNVdZI1XVFRUVYsmQJDh48WGEAJRaLIRKJ3mwg9ddffwlqjIiIiOhNWbt2Lfbv34+mTZtiyJAhsLS0hIaGck/H41l7REREKkaZR8TUZ0eOHEGzZs1w4MABhY+zeV2C3qs+ffpINseqyI4dO6o8cZqIiIhkqYmU96rPnj17hh49etRYEAUIHJFKTExEZmZmpWUyMzORlJQkqFNERET1mYiLzZXC2toa2dnZNdpGjY0e5uTkQFNTs6aqJyIiIqqUt7c3zpw5g6ysrBprQ+ERqVdHl7KysuSOOJWUlCA5ORkhISFo0qRJ9XtIRERUz9T3KTllmTp1KmJjYzFx4kR89tlnaNu2rdyNxKtD4UCqd+/eEIn+985u37690nVSYrEYn3/+efV6R0REVA9xsblytGnTBkBZTDJp0qQKy1Vnn0uFA6lhw4ZBJBJBLBbjwIEDcHR0RKtWrWTKlR8C2LlzZ3Tr1k1Qp4iIiIiq603se6lwIPXyac4HDhxA3759a/QQQCIiovqKO5srx5vY91LQU3svn6xMREREysU1UnUHp2GJiIjoPy83Nxe3bt1CRESEUusVNCK1cOFChcqJRCKsWLFCSBNERET1FkeklCclJQXLly/HyZMnUVJSIrWwPCIiAv/3f/+HJUuWwMPDQ1D9ggKpwMDASvPLF6UzkCIiInp96rXdgf+I1NRUjBw5Es+ePUPv3r3x7NkzXLt2TZLv7OyMZ8+e4e+//36zgVRoaKjc9KysLERHR2PDhg1wcXHBvHnzBHWKiIiIqLrWr1+P58+f448//oCnpyfWr18vFUhpamrCzc0NV65cEdyGoEDKxsamwjwnJyd069YNQ4cORefOnTFy5EjBnSMiIqqP+NSecpw5cwa9e/eGp6dnhWWsrKyqtW6qRhabW1lZoVevXlUebExERESyeGixcjx9+hS2traVltHU1EReXp7gNgSNSCmiUaNGePjwYU1VT0RE9J9V3wMgZTE2NkZycnKlZe7fvw9TU1PBbdTIiFRJSQnCwsJgYGBQE9UTERERValjx444ceIE0tLS5OY/ePAA586dE7zQHBA4InX58mW56cXFxUhJScH+/fsRExPD9VFEREQCqHNESikmT56M0NBQjBs3DosWLZJM4eXm5uLy5ctYuXIlRCIRPvjgA8FtCAqkxo8fL3WA8avEYjE6deqE+fPnC+4YERFRfcWpPeVwdnbG0qVL8dVXX+Hjjz+WpLu6ugIA1NXVsWLFCrRs2VJwG4ICqRkzZsgNpEQiEYyMjNC+fXu0b99ecKeIiIiIlGHEiBFwc3PDzp07cf36daSnp0NfXx8dOnTA+++/jxYtWlSrfkGB1MyZM6vVKBEREVWM2x8oV7NmzbBo0aIaqZtn7REREakYbn+gHOvXr69wXXe5iIgIrF+/XnAbgrc/CA8Px5UrV5CamgoAMDc3R8eOHeHu7i64M0RERETKUh4gderUqcIyly9fxi+//AJfX19Bbbx2IBUeHo6vvvoK9+/fB1C2sByAZM1UixYt8NVXX1XaaSIiIqoYz9p7c4qLi6GmJnyC7rUCqeDgYMybNw/FxcUwMzODh4cHrKysAADJyckIDw9HfHw8Jk2ahB9++AH9+/cX3DEiIqL6qr5Pyb1JN2/ehImJieDrReLyIaUqPHnyBAMHDkRpaSkWLlyIkSNHQl1dOmYuLS3F3r17sWLFCohEIgQFBcHCwkJw54iIiOqjX2NClFbXx63q16CGj4+P5L/Dw8NhY2Mj94zg0tJSJCcnIykpCV5eXlizZo2g9hQekdq2bRvy8vLw888/o1+/fnLLqKmpYdSoUWjYsCF8fX2xfft2fPbZZ4I6Vhts2i6p7S6Qiki8sRQ9j56v7W6Qijjl1RXFpddruxukQjTUnGu0fj61J1x4eLjkv0UiERITE5GYmChTTk1NDcbGxhg0aFC1nuhTOJA6e/YsnJ2dKwyiXta3b184OzvjzJkzdSqQIiIiUgXc2Vy42NhYyX87OTnB19dX8EJyRSi8uiopKQkuLi4KV+zi4iI3AiQiIqLKcfsD5Vi5ciX69u1bo20oHEgVFxdDU1NT4Yo1NDRQWloqqFNERERE1RUeHl7loM7JkyexcOFCwW0oHEiZmZkhLi5O4Yrv3r0LU1NTQZ0iIiKqzzgipRyBgYGIiYmptExsbCwOHDgguA2FA6lOnTrh/PnziI+Pr7JsfHw8zp07x72kiIiIBGAg9eYUFhbK7ELwOhQOpN5//30UFxfj448/xt27dyssFx8fj48//hglJSV47733BHeMiIiIqLrKNwyXp7CwEBEREdWaQVP4qb22bdti8uTJ2LJlC7y9vdG/f394enpKbch58eJFHDt2DEVFRZg0aRLatWsnuGNERET1lTq3PxCsT58+Ul9v27YN+/fvlylXWlqK58+fo7CwEGPGjBHc3mvtbP7ZZ59BR0cHv/76K44ePYq///5bKl8sFkNdXR3Tp0/HzJkzBXeKiIioPhN+YAm9vM+4SCSCWCyGvL3HNTQ04ODggM6dO2PatGmC23vts/Z8fX3h7e2Nffv24cqVK0hLSwMAmJqawtXVFd7e3mjSpIngDhEREREJdeLECcl/Ozk5YcKECTW6j9RrB1IAYGNjg1mzZim7L0RERAQuEleW7du3yz0e5mWlpaU4ceKE4P2mBAVSREREVHMYSCmHu7t7hXmJiYkICAjA/v37kZaWVuU2CRVhIEVEREQVCgkJwebNmxEXFwdNTU24urpi7ty5cHBwqPLa06dPY9euXbh9+zZevHgBkUgEGxsbDBgwAD4+PjA0NJSULSgowKFDh3D69GnExsYiNTUVJiYmcHBwwOTJk+Hp6VnteykpKUFoaCh2796NixcvorS0FCKRCF26dBFcJwMpIiIiFaMqT+0FBATgiy++gIODAz799FMUFBTAz88PY8aMgb+/PxwdHSu9/s6dOwCA4cOHw9zcHEVFRYiOjsbGjRtx9OhR7Nu3D7q6ugCAhIQEfPHFF3BxccGwYcNgaWmJlJQU7Nq1CxMmTMCnn36KDz/8UNB9PH78GHv27EFgYCCePXsGADAxMcHo0aMxYsSIKqf/KiMSy1vKXk/ZtF1S210gFZF4Yyl6Hj1f290gFXHKqyuKS6/XdjdIhWioOddo/Qcf/qO0ut6xfVvQdRkZGejduzf09fVx9OhR6OvrAyg7e9fLywvt2rXD9u3bBdX9+++/Y82aNfj2228xbNgwAMCLFy+QlJSENm3aSJVNTU3FkCFDkJOTg/Pnz8PIyEihNoqLi3Hs2DHs2bMHYWFhKC0thaamJnr16oWQkBCMHDkSy5YtE9T/l3FEioiISMWowhqp0NBQZGdnY9KkSZIgCgCsra0xYMAABAYGIjk5WbKf5OsoHwHKzMyUpJmYmMDExESmrLm5OTp16oRjx47h/v376NChQ6V1P3jwAHv27MGBAwfw4sULiMVitGnTBsOHD8fgwYNhZGQEJyen1+5zRRhIERERkYzr18tGYV1cXGTyXFxcEBgYiOjoaIUCqZycHBQUFCA3Nxe3bt3CmjVroKmpia5duyrUlydPngAAGjVqVGXZgQMHQiQSoVGjRpg4cSKGDx+Oli1bKtSOEAykiIiIVIwyR6Re3en7VaGhoXLTy4MXS0tLmbzytJSUFIX6sGzZMgQGBkq+btmyJTZs2AA7O7sqrz1x4gSioqLg7u6u8D6VIpEIb731FgYMGFCjQRTAQIqIiEjlqKvA1F5eXh4AQEtLSyavPC0/P1+huqZMmYKhQ4ciPT0dV65cQUREBNLT06u87u7du1iwYAGMjIywYsUKhdr65JNPsHfvXuzfvx+BgYFo3rw5vL298c4778Dc3FyhOl4HAykiIqL/sIpGnKqio6MDoOxg31eVp2lraytUl729Pezt7QEAgwYNQnBwMGbNmgV1dXV4eXnJvebevXuYOHEiSktLsWXLFoVHo6ZNm4Zp06bh7NmzCAgIwIkTJ/D999/jp59+QteuXSWL25WFx/kQERGpGDWRWGkvoSwsLADIn74rT5M37aeI/v37Q09PD7t27ZKbf/fuXfj4+KCgoAB//vlnlQvM5enevTvWrVuH06dPY+7cubC2tsaZM2cwb948iEQixMTE4MaNG4L6/zIGUkRERCpGTYkvodq3bw8AuHr1qkzetWvXAADt2rUTVHdJSQmKioqQkZEhkxcXFwcfHx8UFRVh69atkn4I1ahRI0ydOhXHjh3Dn3/+iQEDBkBDQwM3btzAyJEjMWzYMOzYsUNw/QykiIiISEbfvn2hp6eHgIAAZGdnS9KTkpIQFBQEd3d3yRN7eXl5iI+PR2pqqlQdaWlpcuv29/dHYWGhzEhTbGwsfHx8UFpaim3btsnsKVVdnTt3xk8//YTTp0/js88+g62tLWJjY/HNN98IrpNrpIiIiFSMKuwjZWRkhPnz52PJkiUYO3YsRo8ejcLCQvj5+QEAFi9eLCkbFRUFHx8feHt7Y9WqVZL0wYMHw8XFBW3btoWFhQUyMjIQHh6O06dPw8bGBr6+vpKySUlJmDBhAtLT0zF16lTcvn0bt2/flupT165dYWpqWu17a9iwISZPnozJkycjLCwMAQEBgutiIEVERKRiVOGpPQAYM2YMjI2NsWXLFqxevRqamppwc3PD7NmzFdrU0sfHBxcuXIC/vz/S09OhpaUFW1tbTJ8+HRMnTpTapfzx48eSJ/l+++03ufVt375dKYHUyzw8PODh4SH4eh4R8xIeEUPleEQMvYxHxNCravqImNPJfyutrh5Wg5RWF8niiBQREZGKqc7TdvRmMZAiIiJSMaqwRooUw0CKiIhIxTCQqju4/QERERGRQByRIiIiUjEc5ag7GEgRERGpGBGn9uoMBr1EREREAnFEioiISMVwQKruYCBFRESkYji1V3dwao+IiIhIII5IERERqRiOctQdDKSIiIhUjIhHxNQZDHqJiIiIBOKIFBERkYrhWvO6g4EUERGRiuFTe3UHAykiIiIVwziq7uAaKSIiIiKBOCJFRESkYtQ4JFVnMJAiIiJSMYyj6g5O7REREREJxBEpIiIiFcOn9uoOBlJEREQqhnFU3cGpPSIiIiKBOCJFRESkYjgiVXcwkCIiIlIx3P6g7uDUHhEREZFAHJEiIiJSMRyQqjsYSP0HWFkY4lPfXujZ1R4mxrpITctC8IlY/LDxFDIy8xWq4+NJXdGlUzM42JmhoYkuSkvFSEjKwNmL8fht+0UkP8ms8Fqvfq3x3ghXtG9tBV1dLTx7noMbMSlYv/ksrkQlKOs2SUFm2lqY5NAU7mYmMNTUwPOCQpx78hxb4x4hu7hEoTpGt7CBSyNDNNPXhZGWJkrFYjzJK0DE03QE3E9CWn6hVHldDXV84NAUDkZ6sNbVgaGmBnKKi5GSV4DQxDQcefwE+SWlNXG7VA0pKc+w/ufdOHf2OtLTs2BmZoLefTph+owRMDLSV6iOP7YcQnjYTcTHJ+BFeibURGqwtjZF5y7tMWHiYFhaNqrhu/hvEonEtd0FUpBILBbz3fqXTdsltd2F12bbxAQH/abArJE+gkJjcPf+U7i0s0FXjxa4ey8Nw8ZvwYuMvCrrOff3LOTmFuLW7SdIe5YNTQ11tGlliS6dmiMzKx8jJv2Jm7EpUteoq6vhp+XeGD64Pe49eIozF+8hKzsfZqb6cHVugj93hmPbrvCauvUalXhjKXoePV/b3Xht1rraWN+lHRo20MK5lGd4lJ0HJ2N9dDQ1xqPsXPheiEZmUXGV9ezo2RF5xSW4m5WLFwWF0BCpoaWRHjo0MkJ2UTFmX7qBu5k5kvKWOg2wtYcLYtOzkZCTh/TCIuhpaKCjqRFs9XVxPysXMy5EIVfBQE7VnPLqiuLS67XdDaV69CgF4977Es+eZaB3Hzc0b26D6Oi7CA+7iebNreG3YxmMTQyqrGfggJnQ1dWGo6MtGjUyRnFxMWJjHuDy5VvQ19fB1m1foVXr5m/gjt4sDTXnGq0/PvOw0uqyMxyitLpIFkek6rgVXwyGWSN9fLHib/y5M0ySvuSzAZg6oQsWfNIHn399pMp6+gzbgIJC2V+w773ritVLh2LBrD7wmb5DKu/TGb0wfHB7rN10GqvXn8SrMbmGBpfgvWmz27ZAwwZaWHvzHgIfJEvSp7dqhlEtbDDF0RY/3Iivsp5JZ66isFT2byyvJhb4rL09pjg2xeeXYyTpqXkF8AoOQ4mcv8sWd2iJfjbmGNrUErvuJQq8M1K2ZV9vwbNnGVi0eBLeH/e2JP3bVduwfdtRrF3rjyVfTa2ynoOHvkeDBloy6QF7juOrJb9h7U+78OtvC5XadyJVwt90dZhtExP07GqPRwkvsNVfeuRnzS8nkZNbgHcHO0NHR7PKuuQFUQBwOPgGAKCFrfTwvFkjfXw0sQsirz3Gdz+fkAmiAKC4mFM5b5K1rjbczUyQnJuPAy8FUQDwZ9xj5BWXoJ+NGbTVq/5nLy+IAoBTyU8BAI31dKTSSwG5QVTZNc/+vUa7ynbpzXj0KAUXzl+HjY0Zxr43QCrPd+Yo6Og2wOFDZ5GbW/XSAHlBFAAMfLsLAODhw2S5+VQ5kUh5L6pZDKTqsC7uZcPlZy7EywQyObmFuHz1MXR1teDavrHgNvr1dAQA3Ip7IpXu1b81Gmhp4GDQDWg30IBXv9aYMbkbJoxxR2tHC8HtkXAujYwAAJfT0vFqSJNXUoLoF5nQ0VBHa+Oqp2sq0sWiIQAg/qVpvSqvMf/3mqxcwe2ScoWH3QQAdOnqDDU16V8Deno6cHFxQl5eAaKu3xHcxqmTEQAAB8emwjtaj6kp8UU1i1N7dZhdM1MAwL2Hz+Tm33/4DD272qNFM1OcC7uvUJ1j3+0IKwtD6OlqwamlBbp7tsDjxBdY+eMxqXId2toAAHS0NXH68Ew0tjaWyj8achOzFgUiP7/oNe+KhGry7yhRQo78NXGJOfmAWdlo0pVnGQrV6dXEAmbaWtDRUEdzA124mhojJTcfv8U+lFteXQSMt28CADDQ1ED7hoZoaaSPK0/TcfRRitxr6M178CAJANCsmZXcfFtbS1w4fx0PHiTDs3M7hercGxCKJ0+eITc3H3Fxj3HpYhSsrc0wd+77Sus3kSpSyUDq/v37WLduHW7fvo1GjRrh3XffxbBhw2TKHT9+HCtXrkRoaOib76QKMNBvAADIzJY//J6VXQAAMDRQfErlveEd0dG5ieTrq9EJ8J2/Dw8eP5cq16ihHgDgM99euHz1MT6Y5Y97D5/Byd4c3yz2glf/NsjJLcScLw68zi1RNehpqgMAcipY0J1dXDZ9q/9vOUV4NbFA65cWHMekZ+Gbq3FIrGDKR10kwkQH6RGI4IRU/HQjvsLpQnrzsv4dHdTX15Wbb2Cg+285xUce9+09gaio/41gtW1nh+9WfwJbW8tq9LT+4pRc3aFygVRaWhrGjBmDjIyyv5jv3buHiIgInDhxAqtXr0aDBg0kZXNzc5GUlFRbXf1PGvL+ZgCAiZEO2ra2woJZffDPno/w8bw9OH3hf4uU1f7ddjc9Iw8TfXciO6csaLsanYhJvjtx9ugsvDvEGd+uC0VKatabvxFSiukXogAAhpoaaGmkhymOttjUzRlLr9zG5afpMuULS8WSpx1NG2jB1dQIHzo1w6ZuzpgffgspeQVvsvv0BvnvXg4ASH+RhVu37mPtWn+MGrEA3/84B926dajdztVBjKPqDpWbPt20aROys7Px9ddfIyIiAkePHkW/fv0QEhKCjz76CAUF/EFcTjLipC9/xEkyYpWl2F5SL3uRkYezF+/hval/Ib+gCOtWDod2g//F3eV1ngu7LwmiyqU+zcbVqASoq6uhfRvr126bhMkpKhuJ0tOQP+Kkr1H2/mUXvf4WBJlFxYh8moHPwm6isKQUizq0hJZa5T8+nhYUIjgxDf8XGYOm+rr4pE2L126Xakb5iFN2tvx1a+UjVgYGeq9dt7GJAbp0bY/fN3+BBtpaWLhgPfJf2XeM6L9E5QKpixcvYtiwYRg1ahT09fVhZ2eHdevWYfbs2bh06RKmT5+OwkL+owSA+AdlT1C9+kRdueb/pt/7t5wQmVn5iLyeANNG+nCwN/9f2/efSvLlKd8IVFu76icGSTke/7s26tUn6srZ/PvUXEVrqBSRXVyCm+lZMGmgheYG8qeFXnUrPRtZRcXo8O9ieKp9zZqV/YHz4IH8J+oePkz5t5z8NVSKMDTUQwdnBzx/nom7dx8Lrqe+4lN7dYfKBVJJSUno0KGDTPrHH3+MhQsX4vz585g5cyaKiriI+UJ42QLyt7rYQfTKvxY9XS10cmmC3NxCRFZzd3FL87I1MiUvbWdw9tI9AIDjS8HVyxzszQAAjxNeVKttUtzVfxeQdzIzlpkW0FFXRzsTQ+QVl+BWevWmWk21yx53r2i7g1fpqKtDV0Nd4fJU89w92gAALpy/jtJS6W1KcnLycPVqLHR0GqC9c8tqtfMktWxtpbq64uvyqIxIiS+qWSoXSOnp6SE/X/4ox4QJE7BgwQKcPn0an3zyCYqLq96h+b/s4eMXOHX+Lpo2NsHEse5SeZ/O6AU93QbYd+Q68vL+F3TaNTeFXXNTqbLWlkYwbSR/CH/cSDe4tGuMxOR0xNz53xYIYZEPcSMmGR6uthjYx0nqmvfedYWDnTnuP3yG6ze5hu1NScrNR3jaC1jpamPYKyMJkxyaQEdDHccS06SOammqp4Omr4xgmWtrwURL/kjikKYWaGVsgCd5Bbj30hYIzQ10oSXnuHoNkQiftG0BdZEIF1MZVKuKpk0t0aWrMxIT0+C/M1gqb/3Pe5CXW4AhQ7tDV/d/ywbu3UvEvVc2VE1KeoqnctbKAcCe3cdwIzoellaN4ODALRBel5pIeS+qWSq32LxJkya4du0axo8fLzd/0qRJKCoqwg8//ICoqKg33DvVs+ibIzjoNwXfLBqEbh7Ncef+U3T894iY+PtP8e1a6ScazxyeCUD6OJx2ra2w6ftRiLz+GA8eP0fasxyYGOmgo3NjtHawRHZOAWYt3I/SV566mr04EHv/nITffxyNY6ficO/hMzjYmaHPWw7IyS3A7MWBMtdQzfrpxj2s79IOn7RpAddGRniYnYdWkiNi8rD5tvS2Bdt7dgQAqeNwHIz08VVHR9x8kYXE3Hy8KCiCoZYGWhsbwM5QD7nFJVhxLQ4vj2N4NbHAwMbmuPEiE0/yCpBdVIJG2lroZGqMRtpaeJSdi40xim3BQW/Gl/83GePe+xIrlv+JS5ei0aJFY0RF3UF42E00a2aFTz4ZK1V+iNccAMDNmD2StJhb9zB3zo9wdnZAU1sLNGpkjPT0LERdv4O4uEfQ1dXGqlUzoa7AJrBEdZXKBVJdunTBn3/+iezsbOjryz80c+rUqSgtLcVPP/0kM6VV3zx8/AKDRm/CpzN6o2c3e/R+qyVS07Kx+a+LCh9aHH0rGVt2XIJ7R1v0ecsBxoY6KCgsxqOEF/h163ls8buEpBTZQ4tj4p5g4KhfMXdaT7zVxQ69u7fE8/Rc7DtyHWt/PY34B/L3t6Kak5Sbj4/OXccH/x5a7GFugmf5hdh7P0nhQ4vjMrKx70Ey2pkYwtO87ODjwlIxknLzsfteIvbKObT4VPJT6Kiro7WJAdqYGEJXXR05xcV4mJ2HPfcTceBBCgpKudO9Kmna1BK7A1Zi/c97cO7sNZw5cxVmpiYYN36QwocWt2rdAuPGv43IyFicOX0VGRnZ0NLSROMmFpg4aTDGjR8EKyvTKushWfX7N1vdonKHFj98+BB79+7FwIED0aZNm0rL7tixAzdu3MDKlSuV0nZdPLSYakZdPbSYasZ/8dBiqp6aPrQ4Je+Q0uqy1BmqtLpIlsqNSNna2mLevHkKlX3/fe6YS0REVJNCQkKwefNmxMXFQVNTE66urpg7dy4cHByqvPb06dPYtWsXbt++jRcvXkAkEsHGxgYDBgyAj48PDA0NpcqfP38eISEhiImJwe3bt5Gfn4/vvvsO77zzTk3dXrVx4pqIiEjFqMpTewEBAZg5cyby8vLw6aef4uOPP8bt27cxZswY3L59u8rr79wp2+1++PDhWLhwIebNm4c2bdpg48aNGD16NHJzpfcyO3z4MPbu3Yv8/HyFAjVVoHIjUkRERPWdKiz/zcjIwKpVq2BpaQl/f3/JuuW3334bXl5eWL58ObZv315pHVOmTMGUKVNk0u3s7LBmzRqEhIRIHQE3Z84cLF26FA0aNMD+/fvrxENlHJEiIiIiGaGhocjOzsbIkSOlHv6ytrbGgAEDEBYWhuRk+Zu6VsXGpuzg+8xM6QeZLCwspI6CqwsYSBEREakYVZjau3697AELFxcXmbzytOjoaIXqysnJwfPnz5GQkICQkBCsWbMGmpqa6Nq1azV6qBo4tUdERKRilDnK0adPn0rzQ0ND5aY/eVK2CbOlpaVMXnlaSkqKQn1YtmwZAgMDJV+3bNkSGzZsgJ2dnULXqzIGUkRERCQjL6/sXE4tLS2ZvPK0ik4iedWUKVMwdOhQpKen48qVK4iIiEB6errS+lqbGEgRERGpGGUuNq9oxKkqOjplx0cVFhbK5JWnaWtry+TJY29vD3t7ewDAoEGDEBwcjFmzZkFdXR1eXl6C+qcquEaKiIhI5dT+KikLCwsA8qfvytPkTfspon///tDT08OuXbsE909VMJAiIiJSMSIl/k+o9u3bAwCuXr0qk3ft2jUAQLt27QTVXVJSgqKiImRkZAjun6pgIEVEREQy+vbtCz09PQQEBCA7O1uSnpSUhKCgILi7u8PKygpA2Xqq+Ph4pKamStWRlpYmt25/f38UFhaiQ4cONdb/N4VrpIiIiFSMSFT74xxGRkaYP38+lixZgrFjx2L06NEoLCyEn58fAGDx4sWSslFRUfDx8YG3tzdWrVolSR88eDBcXFzQtm1bWFhYICMjA+Hh4Th9+jRsbGzg6+sr1WZsbCxOnDgBAIiJiQFQtsYrMTERANC7d284OTnV6H2/LgZSREREKkcFtjYHMGbMGBgbG2PLli1YvXo1NDU14ebmhtmzZysU0Pj4+ODChQvw9/dHeno6tLS0YGtri+nTp2PixIkwMjKSKn/r1i2sXbtWKi04OBjBwcEAytZkqVogJRKLxeLa7oSqsGm7pLa7QCoi8cZS9Dx6vra7QSrilFdXFJder+1ukArRUHOu0frTC/9RWl3GWm8rrS6SxREpIiIiFVOdReL0ZjGQIiIiUjkMpOqK2l/NRkRERFRHcUSKiIhIxajCU3ukGAZSREREKodTe3UFQ14iIiIigTgiRUREpGL41F7dwUCKiIhIxTCQqjsYSBEREakcrrypK/hOEREREQnEESkiIiIVIxJxaq+uYCBFRESkchhI1RWc2iMiIiISiCNSREREKoZP7dUdDKSIiIhUDieM6gq+U0REREQCcUSKiIhIxXBqr+5gIEVERKRiuP1B3cGpPSIiIiKBOCJFRESkcjgiVVcwkCIiIlIxIk4Y1RkMpIiIiFQOR6TqCoa8RERERAJxRIqIiEjF8Km9uoOBFBERkcphIFVXcGqPiIiISCCOSBEREakYPrVXdzCQIiIiUjmc2qsrGPISERERCcQRKSIiIhXDQ4vrDgZSREREKobbH9QdnNojIiIiEogjUkRERCqH4xx1BQMpIiIiFcM1UnUHAykiIiKVw0CqruDYIREREZFAHJEiIiJSMXxqr+5gIEVERKRyOGFUV/CdIiIiIhKII1JEREQqhk/t1R0isVgsru1OEBEREdVFnNojIiIiEoiBFBEREZFADKSIiIiIBGIgRURERCQQAykiIiIigRhIEREREQnEQIqIiIhIIAZSRERERAIxkCIiIiISiIEUERERkUAMpIiIiIgEYiBFREREJBADKSIiIiKBGEgRERERCaRR2x2g2hcSEoLNmzcjLi4OmpqacHV1xdy5c+Hg4FDbXaM37LfffsOtW7dw69YtPHr0CGpqarh161Ztd4tqyYMHD3D48GGcP38ejx8/Rk5ODqytrdGlSxdMnToV5ubmtd1FolonEovF4truBNWegIAAfPHFF3BwcMDo0aNRUFAAPz8/ZGRkwN/fH46OjrXdRXqDHB0dYWhoiFatWuHevXt4/vw5A6l6bM2aNdixYwd69eoFZ2dnaGtr49q1azh48CD09fXh7+8POzu72u4mUa1iIFWPZWRkoHfv3tDX18fRo0ehr68PAEhKSoKXlxfatWuH7du313Iv6U169OgRmjZtCgAYP348IiMjGUjVY9HR0bC1tYWhoaFU+u7du/F///d/GDhwINauXVtLvSNSDVwjVY+FhoYiOzsbI0eOlARRAGBtbY0BAwYgLCwMycnJtdhDetPKgygiAGjXrp1MEAUAXl5eAIDbt2+/6S4RqRwGUvXY9evXAQAuLi4yeeVp0dHRb7RPRKT6njx5AgAwNTWt5Z4Q1T4GUvVY+Q9DS0tLmbzytJSUlDfaJyJSfeXTecOHD6/lnhDVPgZS9VheXh4AQEtLSyavPC0/P/+N9omIVNuvv/6K4OBg9O3bF97e3rXdHaJax0CqHtPR0QEAFBYWyuSVp2lra7/RPhGR6tq2bRt+/PFHuLu7Y82aNRCJRLXdJaJax0CqHrOwsAAgf/quPE3etB8R1T9//vknVqxYgc6dO+O3336T/CFGVN8xkKrH2rdvDwC4evWqTN61a9cAlD21Q0T122+//YZVq1ahe/fu2LRpE4MoopcwkKrH+vbtCz09PQQEBCA7O1uSnpSUhKCgILi7u8PKyqoWe0hEte3XX3/F999/j169emHDhg1o0KBBbXeJSKXwiJh6zMjICPPnz8eSJUswduxYjB49GoWFhfDz8wMALF68uJZ7SG/agQMHkJSUBABITEyEWCzGhg0bJPnTp0+vra5RLdixYwd+/PFHmJqaol+/fvjnn3+k8vX09NC3b99a6h2RauDO5oSgoCBs2bJFctaem5sbZs+eDScnp9ruGr1h48ePR3h4eIX53ICxfvn8888RGBhYYb6NjQ1OnDjxBntEpHoYSBEREREJxDVSRERERAIxkCIiIiISiIEUERERkUAMpIiIiIgEYiBFREREJBADKSIiIiKBGEgRERERCcRAioiIiEggBlJEREREAjGQIqIat3//fjg6OmL//v213RUiIqXiocVECnJ0dARQd86b6927NwAofBbazz//jPXr1ytcP89ZIyJiIEVE/3J3d4evr69UWkxMDEJDQ+Hk5IS+fftK5RkYGLzJ7hERqSQGUkQEAPDw8ICHh4dU2v79+xEaGopWrVph5syZtdQzIiLVxTVSRNWQkJAAR0dHfP7550hISMCcOXPg4eGBdu3aYfjw4Th58qTMNS+vFzp16hTGjBmDDh06oFOnTpg1axYePHggc8348eMlU4uV1QcAYWFhcHR0RGJiIhITE+Ho6Ch5ff7550q799TUVCxduhS9e/dG27Zt4enpCV9fX9y4cUPhOjIyMvD+++/DyckJmzZtkqQXFxdjx44dGDVqFDp27AhnZ2cMGzYMfn5+KC0tlapDyHtQWFiI7du3w9vbG506dYKzszN69+6NadOm4cKFC8K/KURU73BEikgJEhMTMXLkSDRp0gTvvPMOMjIy8Pfff2P69On4888/4enpKXNNSEgIzp49i759+8Ld3R0xMTEIDg5GWFgY/P390aJFC0F9sbGxga+vL7Zt2wYAmDBhgiSvVatWwm7wFY8fP8Z7772H1NRUeHp6wsvLC8nJyQgKCsKpU6fw888/o1evXpXWkZSUhClTpuDRo0f49ttv8c477wAAioqK8PHHH+PcuXNo3rw5Bg8ejAYNGiAsLAzLli3D9evXsXr1apn6Xuc9WLhwIY4cOQIHBwe888470NbWRmpqKiIjI3H27Fl06dJFKd8nIvrvYyBFpATh4eGYOXOm1BqjwYMHY8qUKdiyZYvcQOrkyZP49ddfpQKObdu2YcWKFVi6dKkkEHpdjRs3xsyZMxEYGAgANTIl99VXXyE1NRWzZ8/GtGnTJOnvvfcexo0bh88//xwnTpyAnp6e3OtjY2MxZcoU5OXl4bfffpMKXH799VecO3cO48aNw6JFi6Curg4AKCkpwZdffol9+/ZhwIABMmu2FH0PsrKycPToUbRp0wYBAQGS+su9ePGiet8cIqpXOLVHpAQ2NjZSAQUAdO/eHdbW1oiKipJ7jaenp8yozbhx49C0aVNcunQJiYmJNdbf6khJScG5c+dgbW2NKVOmSOV17NgRXl5eSE9Px7Fjx+Ref/78ebz33nsQiUTYsWOHVBBVWloKPz8/mJmZYeHChVJBjrq6Oj7//HOIRCIcPnxYpl5F3wORSASxWAwtLS2oqcn+CDQxMVHsG0FEBI5IESmFk5OTzMgGAFhaWuLatWtyr+nUqZNMmrq6OlxdXfHo0SPExMTAxsZG2V2ttlu3bgEAXF1doampKZPv6emJQ4cO4datWxg2bJhUXnBwMM6fPw9bW1v8/vvvsLa2lsq/f/8+0tPT0axZM2zcuFFu+9ra2rh3755MuqLvgb6+Pnr16oWTJ0/inXfeQf/+/eHm5gZnZ2fo6OhUdftERFIYSBEpgaGhodx0DQ0NmcXR5UxNTStNz8rKUk7nlKy8X2ZmZnLzy9Pl9f/atWsoKipC+/btYWVlJZOfnp4OAHjw4EGle1rl5OTIpL3Oe/DTTz/h999/x5EjR/Dzzz8DABo0aIABAwZgwYIFFb43RESvYiBFVEuePn1aafrL+zSJRCIAZU+zaWhI/7PNzMysoR7KV96vivqflpYGoGzk51Vz5szB6dOnJU8YLl++XGp6rbzufv36vdbmoK9LW1sbM2fOxMyZM5GcnIzLly8jMDAQhw4dQmJiInbu3FljbRPRfwvXSBHVksuXL8uklZSUIDIyEoD0E3ZGRkYAgOTkZJlrKtpuQE1NDSUlJcroqpTWrVsDACIjI1FcXCyTHxYWBgBo06aNTJ6WlhbWrVuHgQMHYv/+/fjss8+k6mjRogUMDQ0lI1dvgpWVFYYOHYotW7bA1tYWkZGRXHBORApjIEVUSy5duiSzx5Gfnx8ePXoEDw8PqfVR7dq1AwAEBARIlb948SKOHj0qt35jY2M8f/4c+fn5Su23paUlunbtisTERJknC69fv44jR47AyMhI5qm6cpqamvjhhx8wdOhQHDlyBHPmzJEETRoaGhg3bhzS0tLwzTffyO17amoq7t69K7j/z58/l3vMT25uLnJzc6GhoSF37RcRkTyc2iOqJb169YKvry/69u0LW1tbxMTE4MyZMzA2NsaSJUukyr777rvYsmULNm3ahNjYWNjZ2eHBgwc4e/Ys+vXrh+DgYJn6O3fujOjoaEyZMgVubm7Q0tKCk5OT5Ay+6li6dCnGjh2L7777DufPn0fbtm0l+0ipqalhxYoVcqf2yqmrq+Pbb79FgwYNEBAQgJkzZ2LdunXQ0tLC9OnTERsbi127duHkyZPw9PSEhYUFnj17hocPH+LKlSuYM2cO7O3tBfX9yZMnGDZsGBwcHODo6AgrKytkZ2fj1KlTSEtLw/jx4yvtOxHRyxhIEdWS/v37Y/To0fj1119x+vRpaGhooH///pg7dy6aN28uVbZRo0bw8/PDd999h8uXL+Py5cto27Yt/vjjDyQkJMgNpKZNm4bMzEycPHkSV65cQUlJCby9vZUSSDVp0gT79u3Dhg0bcObMGYSHh0NPTw/du3fHxx9/jPbt21dZh5qaGpYtW4YGDRrAz88P06ZNwy+//AJtbW1s2LABBw8eRGBgIE6dOoXc3FyYmJigcePG+OSTTzBkyBDBfbexscHMmTMRHh6OsLAwvHjxAsbGxmjevDnmzZsHLy8vwXUTUf0jEovF4truBFF9sn//fixcuBArV67E8OHDa7s7RERUDVwjRURERCQQAykiIiIigRhIEREREQnENVJEREREAnFEioiIiEggBlJEREREAjGQIiIiIhKIgRQRERGRQAykiIiIiARiIEVEREQkEAMpIiIiIoEYSBEREREJ9P9nJc6j6B86FwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def visualize_attention(attention_weights):\n",
    "    # Create heatmap using seaborn\n",
    "    sns.set(font_scale=1.2)\n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(\n",
    "        attention_weights,\n",
    "        cmap=\"YlGnBu\",\n",
    "        linewidths=0.5,\n",
    "        annot=True,\n",
    "        xticklabels=True,\n",
    "        yticklabels=True,\n",
    "        cbar_kws={'label': 'Attention Weight'}\n",
    "    )\n",
    "    ax.set_title('Self-Attention Weights')\n",
    "    plt.xlabel('Input Tokens')\n",
    "    plt.ylabel('Output Tokens')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_attention(attn_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBm9jbpSN6-L"
   },
   "source": [
    "Now that we have a way to calculate self-attention, let's actually generate the input *queries*, *keys*, and *values* for multiple heads. It's easier to understand things this way and we can certainly code it this way as well. But we can also \"simulate\" different heads with a single query matrix, single key matrix, and single value matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJLyGtqbX3uW",
    "outputId": "88fb586c-b007-4534-f973-1a94c290f1df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of each head: 4\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 3\n",
    "embed_dim = 12\n",
    "num_heads = 3\n",
    "head_dim = embed_dim // num_heads\n",
    "\n",
    "print(f\"Dimension of each head: {head_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDl37YzAf7bh"
   },
   "source": [
    "**Using separate weight matrices per head**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ_KoJq3fv-A"
   },
   "source": [
    "Suppose these are our input embeddings. Here we have a batch of 1 containing a sequence of length 3, with each element being a 12-dimensional embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NcX3KBrX3uW",
    "outputId": "e3c2cc7d-8b2b-464e-fa6b-6cfc166fdd46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 3, 12) \n",
      "\n",
      "Input:\n",
      " [[[0.7 1.  0.8 1.  0.5 0.1 0.2 0.1 0.5 1.  0.9 0.1]\n",
      "  [0.  1.  0.1 0.9 0.9 0.6 0.5 0.2 0.2 0.6 0.5 0.4]\n",
      "  [0.9 0.8 0.4 0.3 0.2 0.8 0.5 0.3 0.9 0.7 0.2 0.8]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(batch_size, seq_len, embed_dim).round(1).astype('float32')\n",
    "print(\"Input shape: \", x.shape, \"\\n\")\n",
    "print(\"Input:\\n\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvJicbp6f7pI"
   },
   "source": [
    "We'll declare three sets of *query* weights (one for each head), three sets of *key* weights, and three sets of *value* weights. Remember each weight matrix should have a dimension of $\\text{d}\\ \\text{x}\\ \\text{d/h}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "8zdg7rqrX3uX"
   },
   "outputs": [],
   "source": [
    "# The query weights for each head.\n",
    "wq0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
    "wq1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
    "wq2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
    "\n",
    "# The key weights for each head.\n",
    "wk0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
    "wk1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
    "wk2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
    "\n",
    "# The value weights for each head.\n",
    "wv0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
    "wv1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
    "wv2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzMRHZooX3uX",
    "outputId": "c8e66d10-d4e5-4edc-94be-aa59effa6cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three sets of query weights (one for each head):\n",
      "wq0:\n",
      " [[0.2 0.4 0.7 0.3]\n",
      " [0.1 0.1 0.4 0.1]\n",
      " [0.1 0.  0.8 0.5]\n",
      " [0.6 0.3 0.2 0.3]\n",
      " [0.  0.7 0.1 0.5]\n",
      " [0.  0.4 0.2 1. ]\n",
      " [0.6 0.9 0.1 0.2]\n",
      " [0.6 0.9 0.4 0.8]\n",
      " [0.7 0.8 0.6 0.4]\n",
      " [1.  0.9 0.3 0.3]\n",
      " [0.6 0.2 0.6 0.6]\n",
      " [0.5 0.8 0.7 0.6]]\n",
      "wq1:\n",
      " [[1.  0.1 0.7 0. ]\n",
      " [0.1 0.7 0.7 0.2]\n",
      " [0.  0.9 1.  0.7]\n",
      " [0.2 0.2 0.2 0.5]\n",
      " [0.  0.4 0.4 0.4]\n",
      " [0.3 0.7 1.  0.2]\n",
      " [0.5 0.7 0.7 0.5]\n",
      " [0.5 0.5 0.2 0.7]\n",
      " [0.8 0.1 0.4 0.4]\n",
      " [0.9 0.8 0.8 0.4]\n",
      " [0.3 0.6 0.2 0.9]\n",
      " [0.  0.3 0.3 0.1]]\n",
      "wq2:\n",
      " [[1.  0.1 0.7 0. ]\n",
      " [0.1 0.7 0.7 0.2]\n",
      " [0.  0.9 1.  0.7]\n",
      " [0.2 0.2 0.2 0.5]\n",
      " [0.  0.4 0.4 0.4]\n",
      " [0.3 0.7 1.  0.2]\n",
      " [0.5 0.7 0.7 0.5]\n",
      " [0.5 0.5 0.2 0.7]\n",
      " [0.8 0.1 0.4 0.4]\n",
      " [0.9 0.8 0.8 0.4]\n",
      " [0.3 0.6 0.2 0.9]\n",
      " [0.  0.3 0.3 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The three sets of query weights (one for each head):\")\n",
    "print(\"wq0:\\n\", wq0)\n",
    "print(\"wq1:\\n\", wq1)\n",
    "print(\"wq2:\\n\", wq1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmwGKV9qgch-"
   },
   "source": [
    "We'll generate our *queries*, *keys*, and *values* for each head by multiplying our input by the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NucbYNNSX3uX"
   },
   "outputs": [],
   "source": [
    "# Geneated queries, keys, and values for the first head.\n",
    "q0 = np.dot(x, wq0)\n",
    "k0 = np.dot(x, wk0)\n",
    "v0 = np.dot(x, wv0)\n",
    "\n",
    "# Geneated queries, keys, and values for the second head.\n",
    "q1 = np.dot(x, wq1)\n",
    "k1 = np.dot(x, wk1)\n",
    "v1 = np.dot(x, wv1)\n",
    "\n",
    "# Geneated queries, keys, and values for the third head.\n",
    "q2 = np.dot(x, wq2)\n",
    "k2 = np.dot(x, wk2)\n",
    "v2 = np.dot(x, wv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIDiwWZ0gqhm"
   },
   "source": [
    "These are the resulting *query*, *key*, and *value* vectors for the first head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMcMmbkqX3uX",
    "outputId": "2480891b-5bba-4f8c-bf6f-38621932dd4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q, K, and V for first head:\n",
      "\n",
      "q0 (1, 3, 4):\n",
      " [[[3.04      2.8999999 3.0700002 2.5800002]\n",
      "  [2.31      2.99      1.8800001 2.53     ]\n",
      "  [2.81      3.7400002 3.1100001 3.0500002]]] \n",
      "\n",
      "k0 (1, 3, 4):\n",
      " [[[4.22      2.6000001 2.61      3.4499998]\n",
      "  [3.46      2.17      2.44      2.3      ]\n",
      "  [4.4       3.5900002 2.6100001 2.61     ]]] \n",
      "\n",
      "v0 (1, 3, 4):\n",
      " [[[3.82      4.29      4.1       3.82     ]\n",
      "  [2.44      3.1100001 3.5       2.97     ]\n",
      "  [4.08      4.01      3.3400002 3.05     ]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q, K, and V for first head:\\n\")\n",
    "\n",
    "print(f\"q0 {q0.shape}:\\n\", q0, \"\\n\")\n",
    "print(f\"k0 {k0.shape}:\\n\", k0, \"\\n\")\n",
    "print(f\"v0 {v0.shape}:\\n\", v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw5CQ9i6qZDv"
   },
   "source": [
    "Now that we have our Q, K, V vectors, we can just pass them to our self-attention operation. Here we're calculating the output and attention weights for the first head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7tHIvXKX3uX",
    "outputId": "197ef32a-6383-4bb2-da38-d8796a619de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from first attention head:  tf.Tensor(\n",
      "[[[3.9736102 4.097434  3.6038165 3.3148232]\n",
      "  [3.966236  4.0927014 3.6033435 3.3131928]\n",
      "  [3.9910035 4.0893154 3.5714192 3.2829633]]], shape=(1, 3, 4), dtype=float32) \n",
      "\n",
      "Attention weights from first head:  tf.Tensor(\n",
      "[[[0.34498388 0.01017921 0.6448369 ]\n",
      "  [0.34336048 0.01493312 0.6417064 ]\n",
      "  [0.3031936  0.00619889 0.69060755]]], shape=(1, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out0, attn_weights0 = scaled_dot_product_attention(q0, k0, v0)\n",
    "\n",
    "print(\"Output from first attention head: \", out0, \"\\n\")\n",
    "print(\"Attention weights from first head: \", attn_weights0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoYEXSm7qr_A"
   },
   "source": [
    "Here are the other two (attention weights are ignored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otnqbaDSqpJ7",
    "outputId": "fbad96fd-1cb7-43db-eafe-164f9dc372ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from second attention head:  tf.Tensor(\n",
      "[[[3.7179255 2.996449  4.6257806 4.6710167]\n",
      "  [3.6674347 3.0228615 4.578984  4.6606913]\n",
      "  [3.7334046 2.9883797 4.6309195 4.6695094]]], shape=(1, 3, 4), dtype=float32) \n",
      "\n",
      "Output from third attention head:  tf.Tensor(\n",
      "[[[2.898529  3.4907331 2.167152  2.8126092]\n",
      "  [2.8497565 3.467297  2.1532092 2.8036847]\n",
      "  [2.878027  3.4812932 2.1601353 2.8079448]]], shape=(1, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out1, _ = scaled_dot_product_attention(q1, k1, v1)\n",
    "out2, _ = scaled_dot_product_attention(q2, k2, v2)\n",
    "\n",
    "print(\"Output from second attention head: \", out1, \"\\n\")\n",
    "print(\"Output from third attention head: \", out2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOV717bqX3uX"
   },
   "source": [
    "As we covered in the slides, once we have each head's output, we concatenate them and then put them through a linear layer for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmSv5trtt2v9",
    "outputId": "be636cd0-75f0-482e-bf7a-30827366162b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined output from all heads (1, 3, 12):\n",
      "[[[3.9736102 4.097434  3.6038165 3.3148232 3.7179255 2.996449  4.6257806\n",
      "   4.6710167 2.898529  3.4907331 2.167152  2.8126092]\n",
      "  [3.966236  4.0927014 3.6033435 3.3131928 3.6674347 3.0228615 4.578984\n",
      "   4.6606913 2.8497565 3.467297  2.1532092 2.8036847]\n",
      "  [3.9910035 4.0893154 3.5714192 3.2829633 3.7334046 2.9883797 4.6309195\n",
      "   4.6695094 2.878027  3.4812932 2.1601353 2.8079448]]]\n"
     ]
    }
   ],
   "source": [
    "combined_out_a = np.concatenate((out0, out1, out2), axis=-1)\n",
    "print(f\"Combined output from all heads {combined_out_a.shape}:\")\n",
    "print(combined_out_a)\n",
    "\n",
    "# The final step would be to run combined_out_a through a linear/dense layer\n",
    "# for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPmbr6F1C-v_"
   },
   "source": [
    "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads.\n",
    "\n",
    "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
    "\n",
    "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hu94p-_-2_BX",
    "outputId": "024e8ba9-f38e-4f90-ec31-cbc2afa9866e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## Positional encoding\n",
    "\n",
    "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence.\n",
    "\n",
    "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
    "\n",
    "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "1kLCla68EloE",
    "outputId": "788e4711-c1c7-4e87-a26e-3ef6de4de95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7BYeBCNvi7n",
    "outputId": "0c4fed4a-44b8-4907-c594-fec5ad127d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxKGuXxaBeeE",
    "outputId": "d0311353-ebb4-4b88-86a6-0c560cdfda28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mytb1lPyOHLB",
    "outputId": "976ad3d2-e49b-4a27-beb5-2432a7287d3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 50, 512]), TensorShape([64, 50, 512]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape,tf.random.uniform((64, 50, 512)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yScbC0MUH8dS"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfYJG-Kvgwy2"
   },
   "source": [
    "The transformer model follows the same general pattern as a standard [sequence to sequence with attention model](nmt_with_attention.ipynb).\n",
    "\n",
    "* The input sentence is passed through `N` encoder layers that generates an output for each word/token in the sequence.\n",
    "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### Encoder layer\n",
    "\n",
    "Each encoder layer consists of sublayers:\n",
    "\n",
    "1.   Multi-head attention (with padding mask)\n",
    "2.    Point wise feed forward networks.\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
    "\n",
    "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzZRXdO0mI48",
    "outputId": "dae07a3b-18ee-4970-c0c8-2a4f84b6f8a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n",
    "\n",
    "Each decoder layer consists of sublayers:\n",
    "\n",
    "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
    "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
    "3.   Point wise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
    "\n",
    "There are N decoder layers in the transformer.\n",
    "\n",
    "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne2Bqx8k71l0",
    "outputId": "14a054f1-ec4b-4544-8dba-a77b70cb86ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,\n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                            self.d_model)\n",
    "\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QG9nueFQKXx",
    "outputId": "0e02be1a-6dd3-4fc1-8dc4-6af2278e2938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    " The `Decoder` consists of:\n",
    "1.   Output Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1jXoAMRZyvu",
    "outputId": "9f92981c-9bde-4019-cc47-ed7994a81418"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              training=False,\n",
    "                              look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inp, tar, training, enc_padding_mask,\n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJ4fbQcIkHW1",
    "outputId": "6fbdc3cf-7da7-42b1-a018-f4964b1f4024"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=8500, target_vocab_size=8000,\n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
    "                               enc_padding_mask=None,\n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced.\n",
    "\n",
    "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
    "\n",
    "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "8a_CTrcQzJ6U"
   },
   "outputs": [],
   "source": [
    "decay_steps = 10\n",
    "initial_learning_rate = 0.001\n",
    "warmup_steps = 10\n",
    "target_learning_rate = 0.0004\n",
    "lr_warmup_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps, warmup_target=target_learning_rate,\n",
    "    warmup_steps=warmup_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "DwESUUznx0Ke"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.schedules.learning_rate_schedule.CosineDecay at 0x2ad5823ca0b0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_warmup_decayed_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size,\n",
    "                          pe_input=input_vocab_size,\n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by\n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNhuYfllndLZ",
    "outputId": "a3a56ac6-c8f0-4a4b-94ce-6a9eb0e9b362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n",
    "\n",
    "During training this example uses teacher-forcing (like in the [text generation tutorial](./text_generation.ipynb)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peeking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "\n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp,\n",
    "                                 True,\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "Portuguese is used as the input language and English is the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbvmaKNiznHZ",
    "outputId": "6005cf14-07a5-40cd-b678-40947a1cbe94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.2701 Accuracy 0.0815\n",
      "Epoch 1 Batch 50 Loss 7.1104 Accuracy 0.0835\n",
      "Epoch 1 Batch 100 Loss 6.5668 Accuracy 0.0883\n",
      "Epoch 1 Batch 150 Loss 6.2995 Accuracy 0.0915\n",
      "Epoch 1 Batch 200 Loss 6.1047 Accuracy 0.0944\n",
      "Epoch 1 Batch 250 Loss 5.9730 Accuracy 0.0962\n",
      "Epoch 1 Batch 300 Loss 5.8687 Accuracy 0.0979\n",
      "Epoch 1 Batch 350 Loss 5.7833 Accuracy 0.0995\n",
      "Epoch 1 Batch 400 Loss 5.7166 Accuracy 0.1012\n",
      "Epoch 1 Batch 450 Loss 5.6541 Accuracy 0.1027\n",
      "Epoch 1 Batch 500 Loss 5.6077 Accuracy 0.1039\n",
      "Epoch 1 Batch 550 Loss 5.5639 Accuracy 0.1050\n",
      "Epoch 1 Batch 600 Loss 5.5261 Accuracy 0.1061\n",
      "Epoch 1 Batch 650 Loss 5.4904 Accuracy 0.1073\n",
      "Epoch 1 Batch 700 Loss 5.4605 Accuracy 0.1082\n",
      "Epoch 1 Loss 5.4595 Accuracy 0.1082\n",
      "Time taken for 1 epoch: 99.47661542892456 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 5.0477 Accuracy 0.1178\n",
      "Epoch 2 Batch 50 Loss 4.9911 Accuracy 0.1225\n",
      "Epoch 2 Batch 100 Loss 4.9777 Accuracy 0.1233\n",
      "Epoch 2 Batch 150 Loss 4.9724 Accuracy 0.1237\n",
      "Epoch 2 Batch 200 Loss 4.9596 Accuracy 0.1242\n",
      "Epoch 2 Batch 250 Loss 4.9550 Accuracy 0.1244\n",
      "Epoch 2 Batch 300 Loss 4.9501 Accuracy 0.1249\n",
      "Epoch 2 Batch 350 Loss 4.9451 Accuracy 0.1253\n",
      "Epoch 2 Batch 400 Loss 4.9408 Accuracy 0.1259\n",
      "Epoch 2 Batch 450 Loss 4.9299 Accuracy 0.1265\n",
      "Epoch 2 Batch 500 Loss 4.9208 Accuracy 0.1268\n",
      "Epoch 2 Batch 550 Loss 4.9123 Accuracy 0.1273\n",
      "Epoch 2 Batch 600 Loss 4.9042 Accuracy 0.1276\n",
      "Epoch 2 Batch 650 Loss 4.8987 Accuracy 0.1281\n",
      "Epoch 2 Batch 700 Loss 4.8913 Accuracy 0.1285\n",
      "Epoch 2 Loss 4.8910 Accuracy 0.1285\n",
      "Time taken for 1 epoch: 43.564298152923584 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 4.8926 Accuracy 0.1311\n",
      "Epoch 3 Batch 50 Loss 4.7506 Accuracy 0.1324\n",
      "Epoch 3 Batch 100 Loss 4.7491 Accuracy 0.1335\n",
      "Epoch 3 Batch 150 Loss 4.7458 Accuracy 0.1344\n",
      "Epoch 3 Batch 200 Loss 4.7430 Accuracy 0.1348\n",
      "Epoch 3 Batch 250 Loss 4.7400 Accuracy 0.1352\n",
      "Epoch 3 Batch 300 Loss 4.7347 Accuracy 0.1355\n",
      "Epoch 3 Batch 350 Loss 4.7252 Accuracy 0.1359\n",
      "Epoch 3 Batch 400 Loss 4.7231 Accuracy 0.1362\n",
      "Epoch 3 Batch 450 Loss 4.7216 Accuracy 0.1362\n",
      "Epoch 3 Batch 500 Loss 4.7188 Accuracy 0.1364\n",
      "Epoch 3 Batch 550 Loss 4.7149 Accuracy 0.1368\n",
      "Epoch 3 Batch 600 Loss 4.7102 Accuracy 0.1370\n",
      "Epoch 3 Batch 650 Loss 4.7064 Accuracy 0.1372\n",
      "Epoch 3 Batch 700 Loss 4.7025 Accuracy 0.1373\n",
      "Epoch 3 Loss 4.7030 Accuracy 0.1373\n",
      "Time taken for 1 epoch: 40.13032150268555 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.6054 Accuracy 0.1386\n",
      "Epoch 4 Batch 50 Loss 4.6021 Accuracy 0.1401\n",
      "Epoch 4 Batch 100 Loss 4.6052 Accuracy 0.1396\n",
      "Epoch 4 Batch 150 Loss 4.5953 Accuracy 0.1404\n",
      "Epoch 4 Batch 200 Loss 4.5986 Accuracy 0.1410\n",
      "Epoch 4 Batch 250 Loss 4.5963 Accuracy 0.1412\n",
      "Epoch 4 Batch 300 Loss 4.5944 Accuracy 0.1417\n",
      "Epoch 4 Batch 350 Loss 4.5880 Accuracy 0.1421\n",
      "Epoch 4 Batch 400 Loss 4.5893 Accuracy 0.1421\n",
      "Epoch 4 Batch 450 Loss 4.5872 Accuracy 0.1423\n",
      "Epoch 4 Batch 500 Loss 4.5835 Accuracy 0.1427\n",
      "Epoch 4 Batch 550 Loss 4.5802 Accuracy 0.1430\n",
      "Epoch 4 Batch 600 Loss 4.5793 Accuracy 0.1433\n",
      "Epoch 4 Batch 650 Loss 4.5774 Accuracy 0.1434\n",
      "Epoch 4 Batch 700 Loss 4.5743 Accuracy 0.1434\n",
      "Epoch 4 Loss 4.5742 Accuracy 0.1435\n",
      "Time taken for 1 epoch: 40.988160610198975 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 4.5967 Accuracy 0.1484\n",
      "Epoch 5 Batch 50 Loss 4.5001 Accuracy 0.1469\n",
      "Epoch 5 Batch 100 Loss 4.4939 Accuracy 0.1468\n",
      "Epoch 5 Batch 150 Loss 4.4850 Accuracy 0.1473\n",
      "Epoch 5 Batch 200 Loss 4.4890 Accuracy 0.1468\n",
      "Epoch 5 Batch 250 Loss 4.4863 Accuracy 0.1469\n",
      "Epoch 5 Batch 300 Loss 4.4909 Accuracy 0.1472\n",
      "Epoch 5 Batch 350 Loss 4.4834 Accuracy 0.1474\n",
      "Epoch 5 Batch 400 Loss 4.4818 Accuracy 0.1477\n",
      "Epoch 5 Batch 450 Loss 4.4806 Accuracy 0.1479\n",
      "Epoch 5 Batch 500 Loss 4.4801 Accuracy 0.1480\n",
      "Epoch 5 Batch 550 Loss 4.4800 Accuracy 0.1480\n",
      "Epoch 5 Batch 600 Loss 4.4792 Accuracy 0.1482\n",
      "Epoch 5 Batch 650 Loss 4.4735 Accuracy 0.1484\n",
      "Epoch 5 Batch 700 Loss 4.4736 Accuracy 0.1484\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-38\n",
      "Epoch 5 Loss 4.4738 Accuracy 0.1484\n",
      "Time taken for 1 epoch: 41.019869565963745 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 4.3657 Accuracy 0.1394\n",
      "Epoch 6 Batch 50 Loss 4.4043 Accuracy 0.1497\n",
      "Epoch 6 Batch 100 Loss 4.4018 Accuracy 0.1500\n",
      "Epoch 6 Batch 150 Loss 4.4005 Accuracy 0.1506\n",
      "Epoch 6 Batch 200 Loss 4.4060 Accuracy 0.1506\n",
      "Epoch 6 Batch 250 Loss 4.4010 Accuracy 0.1510\n",
      "Epoch 6 Batch 300 Loss 4.4012 Accuracy 0.1514\n",
      "Epoch 6 Batch 350 Loss 4.3976 Accuracy 0.1515\n",
      "Epoch 6 Batch 400 Loss 4.3952 Accuracy 0.1514\n",
      "Epoch 6 Batch 450 Loss 4.3923 Accuracy 0.1514\n",
      "Epoch 6 Batch 500 Loss 4.3931 Accuracy 0.1516\n",
      "Epoch 6 Batch 550 Loss 4.3869 Accuracy 0.1519\n",
      "Epoch 6 Batch 600 Loss 4.3844 Accuracy 0.1522\n",
      "Epoch 6 Batch 650 Loss 4.3848 Accuracy 0.1524\n",
      "Epoch 6 Batch 700 Loss 4.3826 Accuracy 0.1527\n",
      "Epoch 6 Loss 4.3822 Accuracy 0.1527\n",
      "Time taken for 1 epoch: 39.7160382270813 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 4.4081 Accuracy 0.1647\n",
      "Epoch 7 Batch 50 Loss 4.3100 Accuracy 0.1559\n",
      "Epoch 7 Batch 100 Loss 4.3113 Accuracy 0.1550\n",
      "Epoch 7 Batch 150 Loss 4.3170 Accuracy 0.1553\n",
      "Epoch 7 Batch 200 Loss 4.3170 Accuracy 0.1556\n",
      "Epoch 7 Batch 250 Loss 4.3191 Accuracy 0.1555\n",
      "Epoch 7 Batch 300 Loss 4.3145 Accuracy 0.1559\n",
      "Epoch 7 Batch 350 Loss 4.3111 Accuracy 0.1560\n",
      "Epoch 7 Batch 400 Loss 4.3076 Accuracy 0.1562\n",
      "Epoch 7 Batch 450 Loss 4.3070 Accuracy 0.1565\n",
      "Epoch 7 Batch 500 Loss 4.3082 Accuracy 0.1567\n",
      "Epoch 7 Batch 550 Loss 4.3039 Accuracy 0.1570\n",
      "Epoch 7 Batch 600 Loss 4.3034 Accuracy 0.1571\n",
      "Epoch 7 Batch 650 Loss 4.3008 Accuracy 0.1574\n",
      "Epoch 7 Batch 700 Loss 4.3002 Accuracy 0.1576\n",
      "Epoch 7 Loss 4.2995 Accuracy 0.1576\n",
      "Time taken for 1 epoch: 39.56072473526001 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 4.1427 Accuracy 0.1550\n",
      "Epoch 8 Batch 50 Loss 4.2232 Accuracy 0.1579\n",
      "Epoch 8 Batch 100 Loss 4.2243 Accuracy 0.1587\n",
      "Epoch 8 Batch 150 Loss 4.2358 Accuracy 0.1599\n",
      "Epoch 8 Batch 200 Loss 4.2253 Accuracy 0.1603\n",
      "Epoch 8 Batch 250 Loss 4.2248 Accuracy 0.1606\n",
      "Epoch 8 Batch 300 Loss 4.2297 Accuracy 0.1608\n",
      "Epoch 8 Batch 350 Loss 4.2321 Accuracy 0.1611\n",
      "Epoch 8 Batch 400 Loss 4.2318 Accuracy 0.1612\n",
      "Epoch 8 Batch 450 Loss 4.2282 Accuracy 0.1615\n",
      "Epoch 8 Batch 500 Loss 4.2258 Accuracy 0.1617\n",
      "Epoch 8 Batch 550 Loss 4.2242 Accuracy 0.1619\n",
      "Epoch 8 Batch 600 Loss 4.2234 Accuracy 0.1619\n",
      "Epoch 8 Batch 650 Loss 4.2231 Accuracy 0.1618\n",
      "Epoch 8 Batch 700 Loss 4.2208 Accuracy 0.1619\n",
      "Epoch 8 Loss 4.2214 Accuracy 0.1619\n",
      "Time taken for 1 epoch: 39.759947299957275 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 4.1875 Accuracy 0.1791\n",
      "Epoch 9 Batch 50 Loss 4.1642 Accuracy 0.1638\n",
      "Epoch 9 Batch 100 Loss 4.1538 Accuracy 0.1647\n",
      "Epoch 9 Batch 150 Loss 4.1405 Accuracy 0.1648\n",
      "Epoch 9 Batch 200 Loss 4.1497 Accuracy 0.1646\n",
      "Epoch 9 Batch 250 Loss 4.1493 Accuracy 0.1649\n",
      "Epoch 9 Batch 300 Loss 4.1539 Accuracy 0.1647\n",
      "Epoch 9 Batch 350 Loss 4.1524 Accuracy 0.1651\n",
      "Epoch 9 Batch 400 Loss 4.1502 Accuracy 0.1655\n",
      "Epoch 9 Batch 450 Loss 4.1494 Accuracy 0.1655\n",
      "Epoch 9 Batch 500 Loss 4.1497 Accuracy 0.1656\n",
      "Epoch 9 Batch 550 Loss 4.1499 Accuracy 0.1658\n",
      "Epoch 9 Batch 600 Loss 4.1472 Accuracy 0.1661\n",
      "Epoch 9 Batch 650 Loss 4.1441 Accuracy 0.1663\n",
      "Epoch 9 Batch 700 Loss 4.1413 Accuracy 0.1664\n",
      "Epoch 9 Loss 4.1412 Accuracy 0.1664\n",
      "Time taken for 1 epoch: 39.50019907951355 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 4.2656 Accuracy 0.1643\n",
      "Epoch 10 Batch 50 Loss 4.0838 Accuracy 0.1698\n",
      "Epoch 10 Batch 100 Loss 4.0613 Accuracy 0.1696\n",
      "Epoch 10 Batch 150 Loss 4.0636 Accuracy 0.1696\n",
      "Epoch 10 Batch 200 Loss 4.0660 Accuracy 0.1696\n",
      "Epoch 10 Batch 250 Loss 4.0632 Accuracy 0.1700\n",
      "Epoch 10 Batch 300 Loss 4.0664 Accuracy 0.1699\n",
      "Epoch 10 Batch 350 Loss 4.0663 Accuracy 0.1702\n",
      "Epoch 10 Batch 400 Loss 4.0650 Accuracy 0.1707\n",
      "Epoch 10 Batch 450 Loss 4.0659 Accuracy 0.1708\n",
      "Epoch 10 Batch 500 Loss 4.0637 Accuracy 0.1710\n",
      "Epoch 10 Batch 550 Loss 4.0636 Accuracy 0.1712\n",
      "Epoch 10 Batch 600 Loss 4.0611 Accuracy 0.1712\n",
      "Epoch 10 Batch 650 Loss 4.0590 Accuracy 0.1714\n",
      "Epoch 10 Batch 700 Loss 4.0586 Accuracy 0.1714\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-39\n",
      "Epoch 10 Loss 4.0591 Accuracy 0.1714\n",
      "Time taken for 1 epoch: 39.73861217498779 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 4.2893 Accuracy 0.1702\n",
      "Epoch 11 Batch 50 Loss 3.9877 Accuracy 0.1734\n",
      "Epoch 11 Batch 100 Loss 3.9879 Accuracy 0.1734\n",
      "Epoch 11 Batch 150 Loss 3.9892 Accuracy 0.1739\n",
      "Epoch 11 Batch 200 Loss 3.9875 Accuracy 0.1740\n",
      "Epoch 11 Batch 250 Loss 3.9939 Accuracy 0.1745\n",
      "Epoch 11 Batch 300 Loss 3.9991 Accuracy 0.1750\n",
      "Epoch 11 Batch 350 Loss 3.9926 Accuracy 0.1752\n",
      "Epoch 11 Batch 400 Loss 3.9917 Accuracy 0.1754\n",
      "Epoch 11 Batch 450 Loss 3.9899 Accuracy 0.1757\n",
      "Epoch 11 Batch 500 Loss 3.9881 Accuracy 0.1755\n",
      "Epoch 11 Batch 550 Loss 3.9880 Accuracy 0.1754\n",
      "Epoch 11 Batch 600 Loss 3.9876 Accuracy 0.1754\n",
      "Epoch 11 Batch 650 Loss 3.9861 Accuracy 0.1754\n",
      "Epoch 11 Batch 700 Loss 3.9831 Accuracy 0.1755\n",
      "Epoch 11 Loss 3.9831 Accuracy 0.1755\n",
      "Time taken for 1 epoch: 39.01739549636841 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 3.9874 Accuracy 0.1838\n",
      "Epoch 12 Batch 50 Loss 3.9148 Accuracy 0.1785\n",
      "Epoch 12 Batch 100 Loss 3.9192 Accuracy 0.1768\n",
      "Epoch 12 Batch 150 Loss 3.9170 Accuracy 0.1774\n",
      "Epoch 12 Batch 200 Loss 3.9181 Accuracy 0.1779\n",
      "Epoch 12 Batch 250 Loss 3.9173 Accuracy 0.1780\n",
      "Epoch 12 Batch 300 Loss 3.9181 Accuracy 0.1780\n",
      "Epoch 12 Batch 350 Loss 3.9170 Accuracy 0.1784\n",
      "Epoch 12 Batch 400 Loss 3.9141 Accuracy 0.1788\n",
      "Epoch 12 Batch 450 Loss 3.9132 Accuracy 0.1790\n",
      "Epoch 12 Batch 500 Loss 3.9107 Accuracy 0.1793\n",
      "Epoch 12 Batch 550 Loss 3.9115 Accuracy 0.1792\n",
      "Epoch 12 Batch 600 Loss 3.9109 Accuracy 0.1792\n",
      "Epoch 12 Batch 650 Loss 3.9103 Accuracy 0.1795\n",
      "Epoch 12 Batch 700 Loss 3.9087 Accuracy 0.1796\n",
      "Epoch 12 Loss 3.9083 Accuracy 0.1796\n",
      "Time taken for 1 epoch: 39.660420417785645 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 3.9379 Accuracy 0.1747\n",
      "Epoch 13 Batch 50 Loss 3.8525 Accuracy 0.1828\n",
      "Epoch 13 Batch 100 Loss 3.8623 Accuracy 0.1824\n",
      "Epoch 13 Batch 150 Loss 3.8525 Accuracy 0.1828\n",
      "Epoch 13 Batch 200 Loss 3.8506 Accuracy 0.1828\n",
      "Epoch 13 Batch 250 Loss 3.8494 Accuracy 0.1822\n",
      "Epoch 13 Batch 300 Loss 3.8483 Accuracy 0.1823\n",
      "Epoch 13 Batch 350 Loss 3.8476 Accuracy 0.1828\n",
      "Epoch 13 Batch 400 Loss 3.8478 Accuracy 0.1828\n",
      "Epoch 13 Batch 450 Loss 3.8457 Accuracy 0.1831\n",
      "Epoch 13 Batch 500 Loss 3.8418 Accuracy 0.1832\n",
      "Epoch 13 Batch 550 Loss 3.8406 Accuracy 0.1832\n",
      "Epoch 13 Batch 600 Loss 3.8392 Accuracy 0.1831\n",
      "Epoch 13 Batch 650 Loss 3.8404 Accuracy 0.1832\n",
      "Epoch 13 Batch 700 Loss 3.8376 Accuracy 0.1833\n",
      "Epoch 13 Loss 3.8375 Accuracy 0.1833\n",
      "Time taken for 1 epoch: 39.318670988082886 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 3.7618 Accuracy 0.1892\n",
      "Epoch 14 Batch 50 Loss 3.7724 Accuracy 0.1863\n",
      "Epoch 14 Batch 100 Loss 3.7809 Accuracy 0.1859\n",
      "Epoch 14 Batch 150 Loss 3.7789 Accuracy 0.1863\n",
      "Epoch 14 Batch 200 Loss 3.7737 Accuracy 0.1860\n",
      "Epoch 14 Batch 250 Loss 3.7709 Accuracy 0.1864\n",
      "Epoch 14 Batch 300 Loss 3.7725 Accuracy 0.1866\n",
      "Epoch 14 Batch 350 Loss 3.7724 Accuracy 0.1867\n",
      "Epoch 14 Batch 400 Loss 3.7734 Accuracy 0.1868\n",
      "Epoch 14 Batch 450 Loss 3.7740 Accuracy 0.1868\n",
      "Epoch 14 Batch 500 Loss 3.7736 Accuracy 0.1868\n",
      "Epoch 14 Batch 550 Loss 3.7734 Accuracy 0.1870\n",
      "Epoch 14 Batch 600 Loss 3.7701 Accuracy 0.1871\n",
      "Epoch 14 Batch 650 Loss 3.7701 Accuracy 0.1871\n",
      "Epoch 14 Batch 700 Loss 3.7701 Accuracy 0.1871\n",
      "Epoch 14 Loss 3.7700 Accuracy 0.1871\n",
      "Time taken for 1 epoch: 38.97919201850891 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 3.8027 Accuracy 0.1859\n",
      "Epoch 15 Batch 50 Loss 3.7130 Accuracy 0.1914\n",
      "Epoch 15 Batch 100 Loss 3.7100 Accuracy 0.1886\n",
      "Epoch 15 Batch 150 Loss 3.7176 Accuracy 0.1895\n",
      "Epoch 15 Batch 200 Loss 3.7137 Accuracy 0.1897\n",
      "Epoch 15 Batch 250 Loss 3.7224 Accuracy 0.1891\n",
      "Epoch 15 Batch 300 Loss 3.7214 Accuracy 0.1897\n",
      "Epoch 15 Batch 350 Loss 3.7162 Accuracy 0.1896\n",
      "Epoch 15 Batch 400 Loss 3.7153 Accuracy 0.1899\n",
      "Epoch 15 Batch 450 Loss 3.7181 Accuracy 0.1898\n",
      "Epoch 15 Batch 500 Loss 3.7140 Accuracy 0.1901\n",
      "Epoch 15 Batch 550 Loss 3.7114 Accuracy 0.1903\n",
      "Epoch 15 Batch 600 Loss 3.7110 Accuracy 0.1904\n",
      "Epoch 15 Batch 650 Loss 3.7080 Accuracy 0.1905\n",
      "Epoch 15 Batch 700 Loss 3.7056 Accuracy 0.1907\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-40\n",
      "Epoch 15 Loss 3.7051 Accuracy 0.1908\n",
      "Time taken for 1 epoch: 40.048797845840454 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 3.6202 Accuracy 0.1979\n",
      "Epoch 16 Batch 50 Loss 3.6566 Accuracy 0.1901\n",
      "Epoch 16 Batch 100 Loss 3.6590 Accuracy 0.1925\n",
      "Epoch 16 Batch 150 Loss 3.6586 Accuracy 0.1922\n",
      "Epoch 16 Batch 200 Loss 3.6534 Accuracy 0.1931\n",
      "Epoch 16 Batch 250 Loss 3.6529 Accuracy 0.1928\n",
      "Epoch 16 Batch 300 Loss 3.6511 Accuracy 0.1931\n",
      "Epoch 16 Batch 350 Loss 3.6496 Accuracy 0.1934\n",
      "Epoch 16 Batch 400 Loss 3.6464 Accuracy 0.1933\n",
      "Epoch 16 Batch 450 Loss 3.6436 Accuracy 0.1934\n",
      "Epoch 16 Batch 500 Loss 3.6435 Accuracy 0.1937\n",
      "Epoch 16 Batch 550 Loss 3.6437 Accuracy 0.1937\n",
      "Epoch 16 Batch 600 Loss 3.6443 Accuracy 0.1937\n",
      "Epoch 16 Batch 650 Loss 3.6435 Accuracy 0.1940\n",
      "Epoch 16 Batch 700 Loss 3.6427 Accuracy 0.1939\n",
      "Epoch 16 Loss 3.6423 Accuracy 0.1939\n",
      "Time taken for 1 epoch: 38.883655309677124 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 3.4941 Accuracy 0.1975\n",
      "Epoch 17 Batch 50 Loss 3.5617 Accuracy 0.1952\n",
      "Epoch 17 Batch 100 Loss 3.5809 Accuracy 0.1956\n",
      "Epoch 17 Batch 150 Loss 3.5808 Accuracy 0.1960\n",
      "Epoch 17 Batch 200 Loss 3.5820 Accuracy 0.1959\n",
      "Epoch 17 Batch 250 Loss 3.5835 Accuracy 0.1962\n",
      "Epoch 17 Batch 300 Loss 3.5823 Accuracy 0.1966\n",
      "Epoch 17 Batch 350 Loss 3.5819 Accuracy 0.1966\n",
      "Epoch 17 Batch 400 Loss 3.5788 Accuracy 0.1967\n",
      "Epoch 17 Batch 450 Loss 3.5799 Accuracy 0.1965\n",
      "Epoch 17 Batch 500 Loss 3.5795 Accuracy 0.1968\n",
      "Epoch 17 Batch 550 Loss 3.5797 Accuracy 0.1970\n",
      "Epoch 17 Batch 600 Loss 3.5791 Accuracy 0.1970\n",
      "Epoch 17 Batch 650 Loss 3.5800 Accuracy 0.1972\n",
      "Epoch 17 Batch 700 Loss 3.5806 Accuracy 0.1972\n",
      "Epoch 17 Loss 3.5804 Accuracy 0.1972\n",
      "Time taken for 1 epoch: 38.74680495262146 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 3.4384 Accuracy 0.2109\n",
      "Epoch 18 Batch 50 Loss 3.5567 Accuracy 0.1991\n",
      "Epoch 18 Batch 100 Loss 3.5373 Accuracy 0.1997\n",
      "Epoch 18 Batch 150 Loss 3.5447 Accuracy 0.2001\n",
      "Epoch 18 Batch 200 Loss 3.5417 Accuracy 0.1998\n",
      "Epoch 18 Batch 250 Loss 3.5382 Accuracy 0.1991\n",
      "Epoch 18 Batch 300 Loss 3.5313 Accuracy 0.1991\n",
      "Epoch 18 Batch 350 Loss 3.5287 Accuracy 0.1996\n",
      "Epoch 18 Batch 400 Loss 3.5263 Accuracy 0.1995\n",
      "Epoch 18 Batch 450 Loss 3.5275 Accuracy 0.1996\n",
      "Epoch 18 Batch 500 Loss 3.5234 Accuracy 0.1999\n",
      "Epoch 18 Batch 550 Loss 3.5254 Accuracy 0.1999\n",
      "Epoch 18 Batch 600 Loss 3.5243 Accuracy 0.2002\n",
      "Epoch 18 Batch 650 Loss 3.5228 Accuracy 0.2002\n",
      "Epoch 18 Batch 700 Loss 3.5226 Accuracy 0.2003\n",
      "Epoch 18 Loss 3.5228 Accuracy 0.2004\n",
      "Time taken for 1 epoch: 38.9688618183136 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 3.4931 Accuracy 0.1971\n",
      "Epoch 19 Batch 50 Loss 3.4562 Accuracy 0.2026\n",
      "Epoch 19 Batch 100 Loss 3.4716 Accuracy 0.2011\n",
      "Epoch 19 Batch 150 Loss 3.4755 Accuracy 0.2016\n",
      "Epoch 19 Batch 200 Loss 3.4796 Accuracy 0.2014\n",
      "Epoch 19 Batch 250 Loss 3.4815 Accuracy 0.2015\n",
      "Epoch 19 Batch 300 Loss 3.4751 Accuracy 0.2019\n",
      "Epoch 19 Batch 350 Loss 3.4708 Accuracy 0.2022\n",
      "Epoch 19 Batch 400 Loss 3.4675 Accuracy 0.2027\n",
      "Epoch 19 Batch 450 Loss 3.4638 Accuracy 0.2028\n",
      "Epoch 19 Batch 500 Loss 3.4647 Accuracy 0.2028\n",
      "Epoch 19 Batch 550 Loss 3.4642 Accuracy 0.2030\n",
      "Epoch 19 Batch 600 Loss 3.4665 Accuracy 0.2031\n",
      "Epoch 19 Batch 650 Loss 3.4638 Accuracy 0.2034\n",
      "Epoch 19 Batch 700 Loss 3.4650 Accuracy 0.2034\n",
      "Epoch 19 Loss 3.4649 Accuracy 0.2033\n",
      "Time taken for 1 epoch: 39.45621705055237 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 3.5475 Accuracy 0.2069\n",
      "Epoch 20 Batch 50 Loss 3.4338 Accuracy 0.2044\n",
      "Epoch 20 Batch 100 Loss 3.4274 Accuracy 0.2050\n",
      "Epoch 20 Batch 150 Loss 3.4261 Accuracy 0.2056\n",
      "Epoch 20 Batch 200 Loss 3.4257 Accuracy 0.2054\n",
      "Epoch 20 Batch 250 Loss 3.4227 Accuracy 0.2054\n",
      "Epoch 20 Batch 300 Loss 3.4187 Accuracy 0.2051\n",
      "Epoch 20 Batch 350 Loss 3.4140 Accuracy 0.2054\n",
      "Epoch 20 Batch 400 Loss 3.4096 Accuracy 0.2057\n",
      "Epoch 20 Batch 450 Loss 3.4105 Accuracy 0.2058\n",
      "Epoch 20 Batch 500 Loss 3.4116 Accuracy 0.2058\n",
      "Epoch 20 Batch 550 Loss 3.4066 Accuracy 0.2061\n",
      "Epoch 20 Batch 600 Loss 3.4079 Accuracy 0.2064\n",
      "Epoch 20 Batch 650 Loss 3.4090 Accuracy 0.2065\n",
      "Epoch 20 Batch 700 Loss 3.4104 Accuracy 0.2065\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-41\n",
      "Epoch 20 Loss 3.4100 Accuracy 0.2065\n",
      "Time taken for 1 epoch: 39.278547525405884 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 3.4117 Accuracy 0.2002\n",
      "Epoch 21 Batch 50 Loss 3.3448 Accuracy 0.2095\n",
      "Epoch 21 Batch 100 Loss 3.3557 Accuracy 0.2095\n",
      "Epoch 21 Batch 150 Loss 3.3571 Accuracy 0.2087\n",
      "Epoch 21 Batch 200 Loss 3.3621 Accuracy 0.2092\n",
      "Epoch 21 Batch 250 Loss 3.3656 Accuracy 0.2089\n",
      "Epoch 21 Batch 300 Loss 3.3639 Accuracy 0.2091\n",
      "Epoch 21 Batch 350 Loss 3.3608 Accuracy 0.2091\n",
      "Epoch 21 Batch 400 Loss 3.3604 Accuracy 0.2093\n",
      "Epoch 21 Batch 450 Loss 3.3565 Accuracy 0.2094\n",
      "Epoch 21 Batch 500 Loss 3.3557 Accuracy 0.2092\n",
      "Epoch 21 Batch 550 Loss 3.3552 Accuracy 0.2093\n",
      "Epoch 21 Batch 600 Loss 3.3539 Accuracy 0.2095\n",
      "Epoch 21 Batch 650 Loss 3.3537 Accuracy 0.2096\n",
      "Epoch 21 Batch 700 Loss 3.3563 Accuracy 0.2100\n",
      "Epoch 21 Loss 3.3565 Accuracy 0.2100\n",
      "Time taken for 1 epoch: 39.340171098709106 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 3.4807 Accuracy 0.2039\n",
      "Epoch 22 Batch 50 Loss 3.3160 Accuracy 0.2088\n",
      "Epoch 22 Batch 100 Loss 3.3210 Accuracy 0.2100\n",
      "Epoch 22 Batch 150 Loss 3.3125 Accuracy 0.2108\n",
      "Epoch 22 Batch 200 Loss 3.3143 Accuracy 0.2115\n",
      "Epoch 22 Batch 250 Loss 3.3096 Accuracy 0.2111\n",
      "Epoch 22 Batch 300 Loss 3.3079 Accuracy 0.2110\n",
      "Epoch 22 Batch 350 Loss 3.3073 Accuracy 0.2115\n",
      "Epoch 22 Batch 400 Loss 3.3042 Accuracy 0.2121\n",
      "Epoch 22 Batch 450 Loss 3.3043 Accuracy 0.2122\n",
      "Epoch 22 Batch 500 Loss 3.3028 Accuracy 0.2122\n",
      "Epoch 22 Batch 550 Loss 3.3025 Accuracy 0.2121\n",
      "Epoch 22 Batch 600 Loss 3.3016 Accuracy 0.2121\n",
      "Epoch 22 Batch 650 Loss 3.3038 Accuracy 0.2123\n",
      "Epoch 22 Batch 700 Loss 3.3032 Accuracy 0.2125\n",
      "Epoch 22 Loss 3.3033 Accuracy 0.2125\n",
      "Time taken for 1 epoch: 39.466214179992676 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 3.2565 Accuracy 0.2113\n",
      "Epoch 23 Batch 50 Loss 3.2333 Accuracy 0.2160\n",
      "Epoch 23 Batch 100 Loss 3.2563 Accuracy 0.2152\n",
      "Epoch 23 Batch 150 Loss 3.2493 Accuracy 0.2152\n",
      "Epoch 23 Batch 200 Loss 3.2527 Accuracy 0.2153\n",
      "Epoch 23 Batch 250 Loss 3.2506 Accuracy 0.2153\n",
      "Epoch 23 Batch 300 Loss 3.2531 Accuracy 0.2152\n",
      "Epoch 23 Batch 350 Loss 3.2528 Accuracy 0.2150\n",
      "Epoch 23 Batch 400 Loss 3.2563 Accuracy 0.2148\n",
      "Epoch 23 Batch 450 Loss 3.2569 Accuracy 0.2149\n",
      "Epoch 23 Batch 500 Loss 3.2576 Accuracy 0.2151\n",
      "Epoch 23 Batch 550 Loss 3.2542 Accuracy 0.2150\n",
      "Epoch 23 Batch 600 Loss 3.2555 Accuracy 0.2150\n",
      "Epoch 23 Batch 650 Loss 3.2566 Accuracy 0.2151\n",
      "Epoch 23 Batch 700 Loss 3.2537 Accuracy 0.2152\n",
      "Epoch 23 Loss 3.2535 Accuracy 0.2152\n",
      "Time taken for 1 epoch: 39.129019021987915 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 3.2200 Accuracy 0.2154\n",
      "Epoch 24 Batch 50 Loss 3.1879 Accuracy 0.2170\n",
      "Epoch 24 Batch 100 Loss 3.1960 Accuracy 0.2165\n",
      "Epoch 24 Batch 150 Loss 3.1968 Accuracy 0.2169\n",
      "Epoch 24 Batch 200 Loss 3.1976 Accuracy 0.2175\n",
      "Epoch 24 Batch 250 Loss 3.1999 Accuracy 0.2175\n",
      "Epoch 24 Batch 300 Loss 3.2066 Accuracy 0.2176\n",
      "Epoch 24 Batch 350 Loss 3.2056 Accuracy 0.2178\n",
      "Epoch 24 Batch 400 Loss 3.2037 Accuracy 0.2185\n",
      "Epoch 24 Batch 450 Loss 3.2087 Accuracy 0.2184\n",
      "Epoch 24 Batch 500 Loss 3.2076 Accuracy 0.2181\n",
      "Epoch 24 Batch 550 Loss 3.2068 Accuracy 0.2181\n",
      "Epoch 24 Batch 600 Loss 3.2073 Accuracy 0.2181\n",
      "Epoch 24 Batch 650 Loss 3.2063 Accuracy 0.2183\n",
      "Epoch 24 Batch 700 Loss 3.2052 Accuracy 0.2182\n",
      "Epoch 24 Loss 3.2059 Accuracy 0.2183\n",
      "Time taken for 1 epoch: 39.39083123207092 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 3.1677 Accuracy 0.2251\n",
      "Epoch 25 Batch 50 Loss 3.1554 Accuracy 0.2203\n",
      "Epoch 25 Batch 100 Loss 3.1536 Accuracy 0.2208\n",
      "Epoch 25 Batch 150 Loss 3.1539 Accuracy 0.2200\n",
      "Epoch 25 Batch 200 Loss 3.1561 Accuracy 0.2206\n",
      "Epoch 25 Batch 250 Loss 3.1586 Accuracy 0.2198\n",
      "Epoch 25 Batch 300 Loss 3.1640 Accuracy 0.2196\n",
      "Epoch 25 Batch 350 Loss 3.1604 Accuracy 0.2203\n",
      "Epoch 25 Batch 400 Loss 3.1608 Accuracy 0.2200\n",
      "Epoch 25 Batch 450 Loss 3.1586 Accuracy 0.2200\n",
      "Epoch 25 Batch 500 Loss 3.1585 Accuracy 0.2204\n",
      "Epoch 25 Batch 550 Loss 3.1571 Accuracy 0.2203\n",
      "Epoch 25 Batch 600 Loss 3.1555 Accuracy 0.2206\n",
      "Epoch 25 Batch 650 Loss 3.1570 Accuracy 0.2203\n",
      "Epoch 25 Batch 700 Loss 3.1565 Accuracy 0.2203\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-42\n",
      "Epoch 25 Loss 3.1568 Accuracy 0.2203\n",
      "Time taken for 1 epoch: 39.4243049621582 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 3.0707 Accuracy 0.2482\n",
      "Epoch 26 Batch 50 Loss 3.0626 Accuracy 0.2239\n",
      "Epoch 26 Batch 100 Loss 3.0773 Accuracy 0.2216\n",
      "Epoch 26 Batch 150 Loss 3.0841 Accuracy 0.2215\n",
      "Epoch 26 Batch 200 Loss 3.0986 Accuracy 0.2216\n",
      "Epoch 26 Batch 250 Loss 3.0970 Accuracy 0.2221\n",
      "Epoch 26 Batch 300 Loss 3.1026 Accuracy 0.2224\n",
      "Epoch 26 Batch 350 Loss 3.1053 Accuracy 0.2226\n",
      "Epoch 26 Batch 400 Loss 3.1056 Accuracy 0.2229\n",
      "Epoch 26 Batch 450 Loss 3.1049 Accuracy 0.2228\n",
      "Epoch 26 Batch 500 Loss 3.1046 Accuracy 0.2230\n",
      "Epoch 26 Batch 550 Loss 3.1060 Accuracy 0.2229\n",
      "Epoch 26 Batch 600 Loss 3.1085 Accuracy 0.2228\n",
      "Epoch 26 Batch 650 Loss 3.1090 Accuracy 0.2228\n",
      "Epoch 26 Batch 700 Loss 3.1080 Accuracy 0.2228\n",
      "Epoch 26 Loss 3.1080 Accuracy 0.2228\n",
      "Time taken for 1 epoch: 39.103867053985596 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 3.0916 Accuracy 0.2131\n",
      "Epoch 27 Batch 50 Loss 3.0639 Accuracy 0.2251\n",
      "Epoch 27 Batch 100 Loss 3.0509 Accuracy 0.2236\n",
      "Epoch 27 Batch 150 Loss 3.0606 Accuracy 0.2244\n",
      "Epoch 27 Batch 200 Loss 3.0627 Accuracy 0.2249\n",
      "Epoch 27 Batch 250 Loss 3.0542 Accuracy 0.2247\n",
      "Epoch 27 Batch 300 Loss 3.0574 Accuracy 0.2245\n",
      "Epoch 27 Batch 350 Loss 3.0573 Accuracy 0.2252\n",
      "Epoch 27 Batch 400 Loss 3.0580 Accuracy 0.2255\n",
      "Epoch 27 Batch 450 Loss 3.0597 Accuracy 0.2257\n",
      "Epoch 27 Batch 500 Loss 3.0593 Accuracy 0.2256\n",
      "Epoch 27 Batch 550 Loss 3.0610 Accuracy 0.2256\n",
      "Epoch 27 Batch 600 Loss 3.0617 Accuracy 0.2255\n",
      "Epoch 27 Batch 650 Loss 3.0633 Accuracy 0.2254\n",
      "Epoch 27 Batch 700 Loss 3.0629 Accuracy 0.2255\n",
      "Epoch 27 Loss 3.0623 Accuracy 0.2255\n",
      "Time taken for 1 epoch: 39.16173791885376 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 2.9941 Accuracy 0.2282\n",
      "Epoch 28 Batch 50 Loss 3.0194 Accuracy 0.2253\n",
      "Epoch 28 Batch 100 Loss 3.0197 Accuracy 0.2261\n",
      "Epoch 28 Batch 150 Loss 3.0177 Accuracy 0.2265\n",
      "Epoch 28 Batch 200 Loss 3.0194 Accuracy 0.2262\n",
      "Epoch 28 Batch 250 Loss 3.0212 Accuracy 0.2267\n",
      "Epoch 28 Batch 300 Loss 3.0209 Accuracy 0.2273\n",
      "Epoch 28 Batch 350 Loss 3.0172 Accuracy 0.2276\n",
      "Epoch 28 Batch 400 Loss 3.0156 Accuracy 0.2275\n",
      "Epoch 28 Batch 450 Loss 3.0143 Accuracy 0.2276\n",
      "Epoch 28 Batch 500 Loss 3.0144 Accuracy 0.2275\n",
      "Epoch 28 Batch 550 Loss 3.0157 Accuracy 0.2274\n",
      "Epoch 28 Batch 600 Loss 3.0182 Accuracy 0.2273\n",
      "Epoch 28 Batch 650 Loss 3.0172 Accuracy 0.2275\n",
      "Epoch 28 Batch 700 Loss 3.0161 Accuracy 0.2278\n",
      "Epoch 28 Loss 3.0166 Accuracy 0.2278\n",
      "Time taken for 1 epoch: 39.05178761482239 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 2.7496 Accuracy 0.2322\n",
      "Epoch 29 Batch 50 Loss 2.9766 Accuracy 0.2285\n",
      "Epoch 29 Batch 100 Loss 2.9745 Accuracy 0.2285\n",
      "Epoch 29 Batch 150 Loss 2.9695 Accuracy 0.2293\n",
      "Epoch 29 Batch 200 Loss 2.9720 Accuracy 0.2292\n",
      "Epoch 29 Batch 250 Loss 2.9740 Accuracy 0.2297\n",
      "Epoch 29 Batch 300 Loss 2.9779 Accuracy 0.2307\n",
      "Epoch 29 Batch 350 Loss 2.9775 Accuracy 0.2307\n",
      "Epoch 29 Batch 400 Loss 2.9728 Accuracy 0.2304\n",
      "Epoch 29 Batch 450 Loss 2.9764 Accuracy 0.2303\n",
      "Epoch 29 Batch 500 Loss 2.9755 Accuracy 0.2301\n",
      "Epoch 29 Batch 550 Loss 2.9741 Accuracy 0.2302\n",
      "Epoch 29 Batch 600 Loss 2.9740 Accuracy 0.2302\n",
      "Epoch 29 Batch 650 Loss 2.9710 Accuracy 0.2304\n",
      "Epoch 29 Batch 700 Loss 2.9719 Accuracy 0.2305\n",
      "Epoch 29 Loss 2.9718 Accuracy 0.2305\n",
      "Time taken for 1 epoch: 38.716670751571655 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 2.8903 Accuracy 0.2124\n",
      "Epoch 30 Batch 50 Loss 2.9127 Accuracy 0.2331\n",
      "Epoch 30 Batch 100 Loss 2.9297 Accuracy 0.2307\n",
      "Epoch 30 Batch 150 Loss 2.9214 Accuracy 0.2316\n",
      "Epoch 30 Batch 200 Loss 2.9248 Accuracy 0.2309\n",
      "Epoch 30 Batch 250 Loss 2.9221 Accuracy 0.2319\n",
      "Epoch 30 Batch 300 Loss 2.9238 Accuracy 0.2321\n",
      "Epoch 30 Batch 350 Loss 2.9238 Accuracy 0.2318\n",
      "Epoch 30 Batch 400 Loss 2.9266 Accuracy 0.2321\n",
      "Epoch 30 Batch 450 Loss 2.9267 Accuracy 0.2324\n",
      "Epoch 30 Batch 500 Loss 2.9274 Accuracy 0.2325\n",
      "Epoch 30 Batch 550 Loss 2.9302 Accuracy 0.2329\n",
      "Epoch 30 Batch 600 Loss 2.9286 Accuracy 0.2332\n",
      "Epoch 30 Batch 650 Loss 2.9282 Accuracy 0.2334\n",
      "Epoch 30 Batch 700 Loss 2.9274 Accuracy 0.2332\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-43\n",
      "Epoch 30 Loss 2.9270 Accuracy 0.2332\n",
      "Time taken for 1 epoch: 39.24117469787598 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 2.8863 Accuracy 0.2240\n",
      "Epoch 31 Batch 50 Loss 2.8591 Accuracy 0.2363\n",
      "Epoch 31 Batch 100 Loss 2.8766 Accuracy 0.2351\n",
      "Epoch 31 Batch 150 Loss 2.8787 Accuracy 0.2358\n",
      "Epoch 31 Batch 200 Loss 2.8759 Accuracy 0.2349\n",
      "Epoch 31 Batch 250 Loss 2.8769 Accuracy 0.2348\n",
      "Epoch 31 Batch 300 Loss 2.8771 Accuracy 0.2345\n",
      "Epoch 31 Batch 350 Loss 2.8792 Accuracy 0.2350\n",
      "Epoch 31 Batch 400 Loss 2.8790 Accuracy 0.2354\n",
      "Epoch 31 Batch 450 Loss 2.8806 Accuracy 0.2351\n",
      "Epoch 31 Batch 500 Loss 2.8790 Accuracy 0.2353\n",
      "Epoch 31 Batch 550 Loss 2.8784 Accuracy 0.2353\n",
      "Epoch 31 Batch 600 Loss 2.8806 Accuracy 0.2353\n",
      "Epoch 31 Batch 650 Loss 2.8820 Accuracy 0.2352\n",
      "Epoch 31 Batch 700 Loss 2.8845 Accuracy 0.2356\n",
      "Epoch 31 Loss 2.8845 Accuracy 0.2356\n",
      "Time taken for 1 epoch: 38.945194721221924 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 2.8264 Accuracy 0.2463\n",
      "Epoch 32 Batch 50 Loss 2.8282 Accuracy 0.2367\n",
      "Epoch 32 Batch 100 Loss 2.8223 Accuracy 0.2396\n",
      "Epoch 32 Batch 150 Loss 2.8223 Accuracy 0.2393\n",
      "Epoch 32 Batch 200 Loss 2.8243 Accuracy 0.2382\n",
      "Epoch 32 Batch 250 Loss 2.8333 Accuracy 0.2378\n",
      "Epoch 32 Batch 300 Loss 2.8340 Accuracy 0.2384\n",
      "Epoch 32 Batch 350 Loss 2.8348 Accuracy 0.2381\n",
      "Epoch 32 Batch 400 Loss 2.8387 Accuracy 0.2380\n",
      "Epoch 32 Batch 450 Loss 2.8404 Accuracy 0.2380\n",
      "Epoch 32 Batch 500 Loss 2.8416 Accuracy 0.2378\n",
      "Epoch 32 Batch 550 Loss 2.8406 Accuracy 0.2380\n",
      "Epoch 32 Batch 600 Loss 2.8415 Accuracy 0.2380\n",
      "Epoch 32 Batch 650 Loss 2.8411 Accuracy 0.2379\n",
      "Epoch 32 Batch 700 Loss 2.8428 Accuracy 0.2381\n",
      "Epoch 32 Loss 2.8429 Accuracy 0.2381\n",
      "Time taken for 1 epoch: 38.604175329208374 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 2.8759 Accuracy 0.2549\n",
      "Epoch 33 Batch 50 Loss 2.7991 Accuracy 0.2359\n",
      "Epoch 33 Batch 100 Loss 2.7883 Accuracy 0.2390\n",
      "Epoch 33 Batch 150 Loss 2.7985 Accuracy 0.2387\n",
      "Epoch 33 Batch 200 Loss 2.7977 Accuracy 0.2382\n",
      "Epoch 33 Batch 250 Loss 2.7970 Accuracy 0.2380\n",
      "Epoch 33 Batch 300 Loss 2.7976 Accuracy 0.2381\n",
      "Epoch 33 Batch 350 Loss 2.7947 Accuracy 0.2389\n",
      "Epoch 33 Batch 400 Loss 2.7938 Accuracy 0.2390\n",
      "Epoch 33 Batch 450 Loss 2.7951 Accuracy 0.2397\n",
      "Epoch 33 Batch 500 Loss 2.7970 Accuracy 0.2400\n",
      "Epoch 33 Batch 550 Loss 2.7997 Accuracy 0.2399\n",
      "Epoch 33 Batch 600 Loss 2.8009 Accuracy 0.2400\n",
      "Epoch 33 Batch 650 Loss 2.8002 Accuracy 0.2401\n",
      "Epoch 33 Batch 700 Loss 2.7999 Accuracy 0.2403\n",
      "Epoch 33 Loss 2.8003 Accuracy 0.2403\n",
      "Time taken for 1 epoch: 38.9466769695282 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 2.8393 Accuracy 0.2288\n",
      "Epoch 34 Batch 50 Loss 2.7349 Accuracy 0.2432\n",
      "Epoch 34 Batch 100 Loss 2.7579 Accuracy 0.2425\n",
      "Epoch 34 Batch 150 Loss 2.7571 Accuracy 0.2427\n",
      "Epoch 34 Batch 200 Loss 2.7584 Accuracy 0.2421\n",
      "Epoch 34 Batch 250 Loss 2.7635 Accuracy 0.2420\n",
      "Epoch 34 Batch 300 Loss 2.7642 Accuracy 0.2418\n",
      "Epoch 34 Batch 350 Loss 2.7624 Accuracy 0.2423\n",
      "Epoch 34 Batch 400 Loss 2.7587 Accuracy 0.2424\n",
      "Epoch 34 Batch 450 Loss 2.7557 Accuracy 0.2425\n",
      "Epoch 34 Batch 500 Loss 2.7542 Accuracy 0.2428\n",
      "Epoch 34 Batch 550 Loss 2.7523 Accuracy 0.2426\n",
      "Epoch 34 Batch 600 Loss 2.7547 Accuracy 0.2424\n",
      "Epoch 34 Batch 650 Loss 2.7572 Accuracy 0.2426\n",
      "Epoch 34 Batch 700 Loss 2.7586 Accuracy 0.2425\n",
      "Epoch 34 Loss 2.7582 Accuracy 0.2426\n",
      "Time taken for 1 epoch: 39.16782188415527 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 2.6238 Accuracy 0.2643\n",
      "Epoch 35 Batch 50 Loss 2.6976 Accuracy 0.2451\n",
      "Epoch 35 Batch 100 Loss 2.7043 Accuracy 0.2455\n",
      "Epoch 35 Batch 150 Loss 2.7050 Accuracy 0.2454\n",
      "Epoch 35 Batch 200 Loss 2.7123 Accuracy 0.2453\n",
      "Epoch 35 Batch 250 Loss 2.7126 Accuracy 0.2451\n",
      "Epoch 35 Batch 300 Loss 2.7108 Accuracy 0.2454\n",
      "Epoch 35 Batch 350 Loss 2.7118 Accuracy 0.2452\n",
      "Epoch 35 Batch 400 Loss 2.7104 Accuracy 0.2453\n",
      "Epoch 35 Batch 450 Loss 2.7129 Accuracy 0.2455\n",
      "Epoch 35 Batch 500 Loss 2.7141 Accuracy 0.2453\n",
      "Epoch 35 Batch 550 Loss 2.7141 Accuracy 0.2457\n",
      "Epoch 35 Batch 600 Loss 2.7165 Accuracy 0.2454\n",
      "Epoch 35 Batch 650 Loss 2.7185 Accuracy 0.2456\n",
      "Epoch 35 Batch 700 Loss 2.7177 Accuracy 0.2458\n",
      "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-44\n",
      "Epoch 35 Loss 2.7175 Accuracy 0.2458\n",
      "Time taken for 1 epoch: 39.39716291427612 secs\n",
      "\n",
      "Epoch 36 Batch 0 Loss 2.5888 Accuracy 0.2504\n",
      "Epoch 36 Batch 50 Loss 2.6816 Accuracy 0.2438\n",
      "Epoch 36 Batch 100 Loss 2.6847 Accuracy 0.2443\n",
      "Epoch 36 Batch 150 Loss 2.6821 Accuracy 0.2448\n",
      "Epoch 36 Batch 200 Loss 2.6777 Accuracy 0.2450\n",
      "Epoch 36 Batch 250 Loss 2.6775 Accuracy 0.2454\n",
      "Epoch 36 Batch 300 Loss 2.6798 Accuracy 0.2451\n",
      "Epoch 36 Batch 350 Loss 2.6783 Accuracy 0.2462\n",
      "Epoch 36 Batch 400 Loss 2.6811 Accuracy 0.2459\n",
      "Epoch 36 Batch 450 Loss 2.6811 Accuracy 0.2459\n",
      "Epoch 36 Batch 500 Loss 2.6805 Accuracy 0.2462\n",
      "Epoch 36 Batch 550 Loss 2.6812 Accuracy 0.2465\n",
      "Epoch 36 Batch 600 Loss 2.6802 Accuracy 0.2467\n",
      "Epoch 36 Batch 650 Loss 2.6806 Accuracy 0.2470\n",
      "Epoch 36 Batch 700 Loss 2.6785 Accuracy 0.2472\n",
      "Epoch 36 Loss 2.6786 Accuracy 0.2472\n",
      "Time taken for 1 epoch: 38.934261083602905 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 2.4787 Accuracy 0.2315\n",
      "Epoch 37 Batch 50 Loss 2.6205 Accuracy 0.2508\n",
      "Epoch 37 Batch 100 Loss 2.6226 Accuracy 0.2488\n",
      "Epoch 37 Batch 150 Loss 2.6175 Accuracy 0.2475\n",
      "Epoch 37 Batch 200 Loss 2.6236 Accuracy 0.2485\n",
      "Epoch 37 Batch 250 Loss 2.6266 Accuracy 0.2490\n",
      "Epoch 37 Batch 300 Loss 2.6291 Accuracy 0.2494\n",
      "Epoch 37 Batch 350 Loss 2.6273 Accuracy 0.2496\n",
      "Epoch 37 Batch 400 Loss 2.6291 Accuracy 0.2494\n",
      "Epoch 37 Batch 450 Loss 2.6311 Accuracy 0.2494\n",
      "Epoch 37 Batch 500 Loss 2.6345 Accuracy 0.2494\n",
      "Epoch 37 Batch 550 Loss 2.6353 Accuracy 0.2493\n",
      "Epoch 37 Batch 600 Loss 2.6373 Accuracy 0.2494\n",
      "Epoch 37 Batch 650 Loss 2.6385 Accuracy 0.2493\n",
      "Epoch 37 Batch 700 Loss 2.6383 Accuracy 0.2495\n",
      "Epoch 37 Loss 2.6382 Accuracy 0.2495\n",
      "Time taken for 1 epoch: 38.99325251579285 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 2.7521 Accuracy 0.2586\n",
      "Epoch 38 Batch 50 Loss 2.5693 Accuracy 0.2538\n",
      "Epoch 38 Batch 100 Loss 2.5810 Accuracy 0.2533\n",
      "Epoch 38 Batch 150 Loss 2.5903 Accuracy 0.2507\n",
      "Epoch 38 Batch 200 Loss 2.5860 Accuracy 0.2508\n",
      "Epoch 38 Batch 250 Loss 2.5909 Accuracy 0.2504\n",
      "Epoch 38 Batch 300 Loss 2.5959 Accuracy 0.2506\n",
      "Epoch 38 Batch 350 Loss 2.5938 Accuracy 0.2514\n",
      "Epoch 38 Batch 400 Loss 2.5949 Accuracy 0.2512\n",
      "Epoch 38 Batch 450 Loss 2.5983 Accuracy 0.2515\n",
      "Epoch 38 Batch 500 Loss 2.5980 Accuracy 0.2517\n",
      "Epoch 38 Batch 550 Loss 2.5987 Accuracy 0.2513\n",
      "Epoch 38 Batch 600 Loss 2.6002 Accuracy 0.2516\n",
      "Epoch 38 Batch 650 Loss 2.6010 Accuracy 0.2517\n",
      "Epoch 38 Batch 700 Loss 2.6024 Accuracy 0.2519\n",
      "Epoch 38 Loss 2.6022 Accuracy 0.2519\n",
      "Time taken for 1 epoch: 38.694908142089844 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 2.3778 Accuracy 0.2544\n",
      "Epoch 39 Batch 50 Loss 2.5331 Accuracy 0.2514\n",
      "Epoch 39 Batch 100 Loss 2.5405 Accuracy 0.2546\n",
      "Epoch 39 Batch 150 Loss 2.5411 Accuracy 0.2539\n",
      "Epoch 39 Batch 200 Loss 2.5439 Accuracy 0.2545\n",
      "Epoch 39 Batch 250 Loss 2.5529 Accuracy 0.2545\n",
      "Epoch 39 Batch 300 Loss 2.5573 Accuracy 0.2550\n",
      "Epoch 39 Batch 350 Loss 2.5588 Accuracy 0.2545\n",
      "Epoch 39 Batch 400 Loss 2.5615 Accuracy 0.2545\n",
      "Epoch 39 Batch 450 Loss 2.5631 Accuracy 0.2545\n",
      "Epoch 39 Batch 500 Loss 2.5617 Accuracy 0.2548\n",
      "Epoch 39 Batch 550 Loss 2.5613 Accuracy 0.2550\n",
      "Epoch 39 Batch 600 Loss 2.5632 Accuracy 0.2548\n",
      "Epoch 39 Batch 650 Loss 2.5626 Accuracy 0.2547\n",
      "Epoch 39 Batch 700 Loss 2.5629 Accuracy 0.2546\n",
      "Epoch 39 Loss 2.5628 Accuracy 0.2546\n",
      "Time taken for 1 epoch: 38.87351059913635 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 2.5018 Accuracy 0.2558\n",
      "Epoch 40 Batch 50 Loss 2.5013 Accuracy 0.2576\n",
      "Epoch 40 Batch 100 Loss 2.5034 Accuracy 0.2567\n",
      "Epoch 40 Batch 150 Loss 2.5068 Accuracy 0.2557\n",
      "Epoch 40 Batch 200 Loss 2.5100 Accuracy 0.2565\n",
      "Epoch 40 Batch 250 Loss 2.5146 Accuracy 0.2561\n",
      "Epoch 40 Batch 300 Loss 2.5165 Accuracy 0.2561\n",
      "Epoch 40 Batch 350 Loss 2.5196 Accuracy 0.2565\n",
      "Epoch 40 Batch 400 Loss 2.5203 Accuracy 0.2564\n",
      "Epoch 40 Batch 450 Loss 2.5227 Accuracy 0.2566\n",
      "Epoch 40 Batch 500 Loss 2.5254 Accuracy 0.2568\n",
      "Epoch 40 Batch 550 Loss 2.5245 Accuracy 0.2568\n",
      "Epoch 40 Batch 600 Loss 2.5244 Accuracy 0.2568\n",
      "Epoch 40 Batch 650 Loss 2.5233 Accuracy 0.2569\n",
      "Epoch 40 Batch 700 Loss 2.5260 Accuracy 0.2566\n",
      "Saving checkpoint for epoch 40 at ./checkpoints/train/ckpt-45\n",
      "Epoch 40 Loss 2.5257 Accuracy 0.2566\n",
      "Time taken for 1 epoch: 38.880903482437134 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 2.5102 Accuracy 0.2563\n",
      "Epoch 41 Batch 50 Loss 2.4994 Accuracy 0.2617\n",
      "Epoch 41 Batch 100 Loss 2.4880 Accuracy 0.2587\n",
      "Epoch 41 Batch 150 Loss 2.4856 Accuracy 0.2590\n",
      "Epoch 41 Batch 200 Loss 2.4833 Accuracy 0.2593\n",
      "Epoch 41 Batch 250 Loss 2.4859 Accuracy 0.2591\n",
      "Epoch 41 Batch 300 Loss 2.4899 Accuracy 0.2592\n",
      "Epoch 41 Batch 350 Loss 2.4860 Accuracy 0.2592\n",
      "Epoch 41 Batch 400 Loss 2.4864 Accuracy 0.2594\n",
      "Epoch 41 Batch 450 Loss 2.4881 Accuracy 0.2593\n",
      "Epoch 41 Batch 500 Loss 2.4881 Accuracy 0.2595\n",
      "Epoch 41 Batch 550 Loss 2.4904 Accuracy 0.2593\n",
      "Epoch 41 Batch 600 Loss 2.4895 Accuracy 0.2593\n",
      "Epoch 41 Batch 650 Loss 2.4902 Accuracy 0.2590\n",
      "Epoch 41 Batch 700 Loss 2.4899 Accuracy 0.2588\n",
      "Epoch 41 Loss 2.4898 Accuracy 0.2588\n",
      "Time taken for 1 epoch: 38.1318256855011 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 2.2985 Accuracy 0.2392\n",
      "Epoch 42 Batch 50 Loss 2.4524 Accuracy 0.2583\n",
      "Epoch 42 Batch 100 Loss 2.4401 Accuracy 0.2591\n",
      "Epoch 42 Batch 150 Loss 2.4363 Accuracy 0.2608\n",
      "Epoch 42 Batch 200 Loss 2.4455 Accuracy 0.2607\n",
      "Epoch 42 Batch 250 Loss 2.4481 Accuracy 0.2614\n",
      "Epoch 42 Batch 300 Loss 2.4488 Accuracy 0.2611\n",
      "Epoch 42 Batch 350 Loss 2.4491 Accuracy 0.2612\n",
      "Epoch 42 Batch 400 Loss 2.4484 Accuracy 0.2609\n",
      "Epoch 42 Batch 450 Loss 2.4476 Accuracy 0.2609\n",
      "Epoch 42 Batch 500 Loss 2.4491 Accuracy 0.2609\n",
      "Epoch 42 Batch 550 Loss 2.4511 Accuracy 0.2609\n",
      "Epoch 42 Batch 600 Loss 2.4513 Accuracy 0.2611\n",
      "Epoch 42 Batch 650 Loss 2.4527 Accuracy 0.2613\n",
      "Epoch 42 Batch 700 Loss 2.4526 Accuracy 0.2612\n",
      "Epoch 42 Loss 2.4530 Accuracy 0.2613\n",
      "Time taken for 1 epoch: 38.331194162368774 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 2.3907 Accuracy 0.2436\n",
      "Epoch 43 Batch 50 Loss 2.3819 Accuracy 0.2649\n",
      "Epoch 43 Batch 100 Loss 2.4040 Accuracy 0.2632\n",
      "Epoch 43 Batch 150 Loss 2.4022 Accuracy 0.2623\n",
      "Epoch 43 Batch 200 Loss 2.4081 Accuracy 0.2621\n",
      "Epoch 43 Batch 250 Loss 2.4121 Accuracy 0.2626\n",
      "Epoch 43 Batch 300 Loss 2.4190 Accuracy 0.2636\n",
      "Epoch 43 Batch 350 Loss 2.4227 Accuracy 0.2634\n",
      "Epoch 43 Batch 400 Loss 2.4202 Accuracy 0.2636\n",
      "Epoch 43 Batch 450 Loss 2.4162 Accuracy 0.2636\n",
      "Epoch 43 Batch 500 Loss 2.4168 Accuracy 0.2633\n",
      "Epoch 43 Batch 550 Loss 2.4176 Accuracy 0.2632\n",
      "Epoch 43 Batch 600 Loss 2.4184 Accuracy 0.2633\n",
      "Epoch 43 Batch 650 Loss 2.4187 Accuracy 0.2637\n",
      "Epoch 43 Batch 700 Loss 2.4198 Accuracy 0.2636\n",
      "Epoch 43 Loss 2.4197 Accuracy 0.2636\n",
      "Time taken for 1 epoch: 37.97560691833496 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 2.3099 Accuracy 0.2600\n",
      "Epoch 44 Batch 50 Loss 2.3682 Accuracy 0.2650\n",
      "Epoch 44 Batch 100 Loss 2.3654 Accuracy 0.2667\n",
      "Epoch 44 Batch 150 Loss 2.3674 Accuracy 0.2669\n",
      "Epoch 44 Batch 200 Loss 2.3689 Accuracy 0.2666\n",
      "Epoch 44 Batch 250 Loss 2.3721 Accuracy 0.2662\n",
      "Epoch 44 Batch 300 Loss 2.3740 Accuracy 0.2661\n",
      "Epoch 44 Batch 350 Loss 2.3738 Accuracy 0.2662\n",
      "Epoch 44 Batch 400 Loss 2.3754 Accuracy 0.2658\n",
      "Epoch 44 Batch 450 Loss 2.3735 Accuracy 0.2662\n",
      "Epoch 44 Batch 500 Loss 2.3741 Accuracy 0.2664\n",
      "Epoch 44 Batch 550 Loss 2.3747 Accuracy 0.2661\n",
      "Epoch 44 Batch 600 Loss 2.3783 Accuracy 0.2660\n",
      "Epoch 44 Batch 650 Loss 2.3816 Accuracy 0.2655\n",
      "Epoch 44 Batch 700 Loss 2.3835 Accuracy 0.2657\n",
      "Epoch 44 Loss 2.3839 Accuracy 0.2657\n",
      "Time taken for 1 epoch: 38.195067167282104 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 2.3536 Accuracy 0.2652\n",
      "Epoch 45 Batch 50 Loss 2.3498 Accuracy 0.2662\n",
      "Epoch 45 Batch 100 Loss 2.3289 Accuracy 0.2670\n",
      "Epoch 45 Batch 150 Loss 2.3410 Accuracy 0.2657\n",
      "Epoch 45 Batch 200 Loss 2.3498 Accuracy 0.2658\n",
      "Epoch 45 Batch 250 Loss 2.3502 Accuracy 0.2660\n",
      "Epoch 45 Batch 300 Loss 2.3520 Accuracy 0.2668\n",
      "Epoch 45 Batch 350 Loss 2.3490 Accuracy 0.2673\n",
      "Epoch 45 Batch 400 Loss 2.3468 Accuracy 0.2680\n",
      "Epoch 45 Batch 450 Loss 2.3478 Accuracy 0.2677\n",
      "Epoch 45 Batch 500 Loss 2.3465 Accuracy 0.2678\n",
      "Epoch 45 Batch 550 Loss 2.3474 Accuracy 0.2677\n",
      "Epoch 45 Batch 600 Loss 2.3476 Accuracy 0.2682\n",
      "Epoch 45 Batch 650 Loss 2.3482 Accuracy 0.2679\n",
      "Epoch 45 Batch 700 Loss 2.3509 Accuracy 0.2679\n",
      "Saving checkpoint for epoch 45 at ./checkpoints/train/ckpt-46\n",
      "Epoch 45 Loss 2.3507 Accuracy 0.2679\n",
      "Time taken for 1 epoch: 38.27765512466431 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 2.2835 Accuracy 0.2516\n",
      "Epoch 46 Batch 50 Loss 2.3208 Accuracy 0.2669\n",
      "Epoch 46 Batch 100 Loss 2.3119 Accuracy 0.2678\n",
      "Epoch 46 Batch 150 Loss 2.3227 Accuracy 0.2679\n",
      "Epoch 46 Batch 200 Loss 2.3194 Accuracy 0.2689\n",
      "Epoch 46 Batch 250 Loss 2.3148 Accuracy 0.2691\n",
      "Epoch 46 Batch 300 Loss 2.3187 Accuracy 0.2699\n",
      "Epoch 46 Batch 350 Loss 2.3174 Accuracy 0.2708\n",
      "Epoch 46 Batch 400 Loss 2.3182 Accuracy 0.2708\n",
      "Epoch 46 Batch 450 Loss 2.3162 Accuracy 0.2708\n",
      "Epoch 46 Batch 500 Loss 2.3187 Accuracy 0.2704\n",
      "Epoch 46 Batch 550 Loss 2.3188 Accuracy 0.2700\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# inp -> portuguese, tar -> english\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, tar)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset):\n\u001b[0;32m----> 9\u001b[0m   \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Batch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Loss \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m Accuracy \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     13\u001b[0m         epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, batch, train_loss\u001b[38;5;241m.\u001b[39mresult(), train_accuracy\u001b[38;5;241m.\u001b[39mresult()))\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/scratch/user/piyalong/myenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "\n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "\n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
    "                                                train_loss.result(),\n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6APsFrgImLW"
   },
   "source": [
    "The following steps are used for evaluation:\n",
    "\n",
    "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Select the last word and calculate the argmax of that.\n",
    "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
    "\n",
    "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "\n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input,\n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "\n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "\n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "\n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "\n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'],\n",
    "        fontdict=fontdict, rotation=90)\n",
    "\n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result\n",
    "                        if i < tokenizer_en.vocab_size],\n",
    "                       fontdict=fontdict)\n",
    "\n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result\n",
    "                                            if i < tokenizer_en.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "\n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsxrAlvFG8SZ",
    "outputId": "0fb2b4e6-9d76-4879-d65b-f90936cb8b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem that we have to solve a u.s .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EH5y_aqI4t1",
    "outputId": "5e620881-150f-4c4b-c8ec-d169d1dedbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: my neighbors heard about this idea .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-hVCTSUMlkb",
    "outputId": "c0edea95-7ab0-4224-844e-d7e5f917225b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: so i will have a lot of sharing some stories of a little bit of the beautiful things that happened .\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1MxkSZvz0jX"
   },
   "source": [
    "You can pass different layers and attention blocks of the decoder to the `plot` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-kFyiOLH0xg",
    "outputId": "961c2a7d-4dc9-4935-e836-90e463f98d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: this is the first book that i did we do .\n",
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\")\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqQ1fIsLwkGE"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
    "\n",
    "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
